lista_info[c(2, 4)]
# Chunk 48
lista_info[[2]]
# Chunk 49
lista_info$nome
# Chunk 50
lista_1 <- list(1, 2)
lista_2 <- list("Gilberto", "Sassi")
lista_concatenada <- c(lista_1, lista_2)
lista_concatenada
# Chunk 51
library(tidyverse) # carregando o framework tidyverse
data_frame <- tibble(
nome = c("Marx", "Engels", "Rosa", "Lênin", "Olga Benário"),
idade = c(22, 23, 21, 24, 30)
)
glimpse(data_frame)
# Chunk 52
head(data_frame, n=2)
# Chunk 53
tail(data_frame, n=2)
# Chunk 54
#| echo: false
df_equipe <- tibble(
nomes = c("Fidel Castro", "Ernesto 'Che' Guevara", "Célia Sánchez"),
origem = c("Cuba", "Cuba", "Cuba")
)
knitr::kable(df_equipe)
# Chunk 55
library(tidyverse)
library(readxl)
dados_iris <- read_xlsx("dados/brutos/iris.xlsx")
dados_iris <- clean_names(dados_iris)
glimpse(dados_iris)
# Chunk 56
dados_mtcarros <- read_csv2("dados/brutos/mtcarros.csv")
dados_mtcarros <- clean_names(dados_mtcarros)
glimpse(dados_mtcarros)
# Chunk 57
library(readODS)
dados_dentes <- read_ods("dados/brutos/crescimento_dentes.ods")
dados_dentes <- clean_names(dados_dentes)
glimpse(dados_dentes)
# Chunk 61
dados_iris <- read_xlsx("dados/brutos/iris.xlsx")
tab <- tabyl(dados_iris, especies)  |>
adorn_totals()  |>
adorn_pct_formatting(digits = 2) |>
rename(
"Espécies" = especies, "Frequência" = n,
"Porcentagem" = percent
)
tab
# Chunk 62
dados_mtcarros <- read_csv2("dados/brutos/mtcarros.csv")
tab <- tabyl(dados_mtcarros, carburadores)  |>
adorn_totals()  |>
adorn_pct_formatting(digits = 2) |>
rename(
"Carburadores" = carburadores, "Frequência" = n,
"Porcentagem" = percent
)
tab
# Chunk 63
k <- ceiling(1 + log(nrow(dados_iris)))
dados_iris2 <- mutate(
dados_iris,
comprimento_sepala_int = cut(
comprimento_sepala,
breaks = k,
include.lowest = TRUE,
right = FALSE
)
)
glimpse(dados_iris2)
# Chunk 65
#| echo: false
tabyl(dados_iris2, comprimento_sepala_int) |>
adorn_totals() |>
adorn_pct_formatting(digits = 2) |>
rename(
"Comprimento de sépala" = comprimento_sepala_int,
"Frequência absoluta" = n,
"Porcentagem" = percent
)
# Chunk 66
ggplot(dados_iris) +
geom_bar(mapping = aes(especies), fill = "blue") +
labs(x = "Espécies", y = "Frequência") +
theme_minimal()
# Chunk 68
#| echo: false
tab <- tabyl(dados_mtcarros, carburadores) |>
adorn_totals() |>
adorn_pct_formatting(digits = 2) |>
rename(
"Número de carburadores" = carburadores,
"Frequência (absoluta)" = n,
"Porcentagem" = percent
)
tab
# Chunk 70
#| echo: false
#| out.width: 100%
ggplot(dados_mtcarros) +
geom_bar(
mapping = aes(carburadores, after_stat(100 * prop)),
fill = "#002f81"
) +
labs(x = "Número de carburadores", y = "Porcentagem") +
theme_minimal()
# Chunk 72
#| echo: false
#| out.width: 100%
ggplot(dados_iris) +
geom_histogram(
aes(x = comprimento_sepala, y = after_stat(density)),
bins = k,
fill = "#002f81"
) +
theme_minimal() +
labs(
x = "Comprimento de Sépala",
y = "Densidade de Frequência"
)
# Chunk 74
#| echo: false
#| out.width: 100%
ggplot(dados_iris, aes(x = comprimento_sepala, y = after_stat(density))) +
geom_histogram(
bins = k,
fill = "#002f81"
) +
geom_density(size = 2, color = "red") +
theme_minimal() +
labs(
x = "Comprimento de Sépala",
y = "Densidade de Frequência"
)
# Chunk 75
dados_iris |>
summarise(
media = mean(comprimento_sepala),
mediana = median(comprimento_sepala),
dp = sd(comprimento_sepala),
cv = dp / media
)
# Chunk 76
tabela <- dados_iris |>
group_by(especies) |>
summarise(
media = mean(comprimento_sepala),
mediana = median(comprimento_sepala),
dp = sd(comprimento_sepala),
cv = dp / media
)
tabela
# Chunk 77
dados_MB <- read_xlsx("dados/brutos/companhia_MB.xlsx")
p <- c(1/8, 1/4, 1/2, 3/4, 7/8)
salario <- dados_MB$salario
# Chunk 78
(quantil_tipo_1 <- quantile(salario, probs = p, type = 1))
# Chunk 79
(quantil_tipo_2 <- quantile(salario, probs = p, type = 2))
# Chunk 80
(quantil_tipo_3 <- quantile(salario, probs = p, type = 3))
# Chunk 81
(quantil_tipo_4 <- quantile(salario, probs = p, type = 4))
# Chunk 82
(quantil_tipo_5 <- quantile(salario, probs = p, type = 5))
# Chunk 83
(quantil_tipo_6 <- quantile(salario, probs = p, type = 6))
# Chunk 84
(quantil_tipo_7 <- quantile(salario, probs = p, type = 7))
# Chunk 85
(quantil_tipo_8 <- quantile(salario, probs = p, type = 8))
# Chunk 86
(quantil_tipo_9 <- quantile(salario, probs = p, type = 9))
# Chunk 87
#| echo: false
tipos <- seq_len(9) |>
sapply(\(k) quantile(dados_MB$salario, probs = p, type = k)) |>
t()
colnames(tipos) <- format(p * 100, big.mark = ".", decimal.mark = ",") |> paste("%")
rownames(tipos) <- NULL
df_tipos <- as_tibble(tipos) |>
mutate(tipos = paste("tipos", seq_len(9))) |>
dplyr::select(tipos, everything())
knitr::kable(df_tipos, format.args = list(decimal.mark = ",", big.mark = "."),
caption = "Comparação de alguns quantis calculados usando diferentes métodos de aproximação para a variável \\texttt{salario}.")
# Chunk 88
set.seed(12345)
amostra <- rnorm(1000, mean = 500, sd = 100)
# Chunk 89
#| echo: false
tipos <- seq_len(9) |>
sapply(\(k) quantile(amostra, probs = p, type = k)) |>
t()
tipos <- rbind(
qnorm(p, mean = 500, sd = 100),
tipos
)
colnames(tipos) <- format(p * 100, big.mark = ".", decimal.mark = ",") |> paste("%")
rownames(tipos) <- NULL
df_tipos <- as_tibble(tipos) |>
mutate(tipos = c("Quantil populacional", paste("tipos", seq_len(9)))) |>
dplyr::select(tipos, everything())
knitr::kable(df_tipos, format.args = list(decimal.mark = ",", big.mark = "."),
caption = "Comparação de alguns quantis calculados usando diferentes métodos de aproximação para a distribuição normal com média 500 e desvio padrão 100.")
# Chunk 90
dados_iris |>
group_by(especies) |>
summarise(
q1 = quantile(comprimento_sepala, 0.25),
q2 = quantile(comprimento_sepala, 0.5),
q3 = quantile(comprimento_sepala, 0.75),
frequencia = n()
)
# Chunk 91
library(lettervalue)
letter_value(dados_iris$comprimento_sepala, level = 3)
# Chunk 92
valores_letras <- letter_value(rivers)
summary(valores_letras)
# Chunk 93
#| echo: false
#| out.width: 25%
knitr::include_graphics("boxplot.png")
glimpse(dados_iris)
library(KbMvtSkew)
BowleySkew(dados_iris$comprimento_sepala)
hist(dados_iris$comprimento_sepala)
BowleySkew(dados_iris$largura_petala)
hist(dados_iris$largura_sepala)
hist(dados_iris$largura_petala)
hist(dados_iris$comprimento_petala)
hist(rivers)
library(KbMvtSkew)
BowleySkew(rivers)
?rivers
library(pacman)
p_load(tidyverse)
amostra <- rlnorm(1000, sd = 2)
hist(amostra)
amostra <- rlnorm(1000, sd = 1)
hist(amostra)
BowleySkew(amostra)
amostra <- rlnorm(1000, sd = 1.5)
BowleySkew(amostra)
amostra <- rlnorm(1000, sd = 1.75)
BowleySkew(amostra)
amostra <- rlnorm(1000, sd = 1.15)
BowleySkew(amostra)
amostra <- rlnorm(1000, sd = 1.5)
BowleySkew(amostra)
mean(amostra)
mean(amostra - mean(amostra))
mean(amostra < mean(amostra))
mean(amostra > mean(amostra))
library(pacman)
p_load(tidyverse)
amostra <- rlnorm(1000, sd = 1.5)
mean(amostra)
mean(amostra < mean(amostra))
amostra <- rbeta(1000, shape1 = 1, shape2 = 3) * 100
mean(amostra)
mean(amostra < mean(amostra))
hist(amostra)
amostra <- rbeta(1000, shape1 = 3, shape2 = 1) * 100
mean(amostra)
mean(amostra < mean(amostra))
hist(amostra)
amostra <- rbeta(1000, shape1 = 10, shape2 = 1) * 100
mean(amostra)
mean(amostra < mean(amostra))
hist(amostra)
amostra <- rbeta(1000, shape1 = 1, shape2 = 10) * 100
mean(amostra)
mean(amostra < mean(amostra))
hist(amostra)
amostra <- rbeta(1000, shape1 = 1, shape2 = 10) * 100
hist(amostra)
mean(amostra < mean(amostra))
amostra <- rbeta(1000, shape1 = 10, shape2 = 1) * 100
hist(amostra)
mean(amostra < mean(amostra))
p_load(tidyverse, e1071)
skewness(amostra)
?skewness
skewness(amostra, type = 1)
amostra <- rbeta(1000, shape1 = 10, shape2 = 1) * 100
hist(amostra)
skewness(amostra)
mean(amostra < mean(amostra))
mean(amostra > mean(amostra))
# assimetria positiva
amostra <- rbeta(1000, shape1 = 1, shape2 = 10) * 100
hist(amostra)
skewness(amostra)
mean(amostra < mean(amostra))
mean((amostra - mean(amostra))^3)
# assimetria positiva
amostra <- rbeta(1000, shape1 = 1, shape2 = 10) * 100
hist(amostra)
skewness(amostra)
mean(amostra < mean(amostra))
# assimetria negativa
amostra <- rbeta(1000, shape1 = 10, shape2 = 1) * 100
hist(amostra)
skewness(amostra)
mean(amostra < mean(amostra))
mean(amostra - mean(amostra))
mean(amostra < mean(amostra))
mean((amostra - mean(amostra))^3)
# assimetria positiva
amostra <- rbeta(1000, shape1 = 1, shape2 = 10) * 100
hist(amostra)
skewness(amostra)
mean((amostra - mean(amostra))^3)
tamanhos <- c(
15,
25,
seq(from = 30, to = 100, by = 10),
150,
seq(from = 200, to = 500, by = 100)
)
tamanho
tamanhos
lower <- seq_along(tamanhos) |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.05)
})
n <- 5000
lower <- seq_along(tamanhos) |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.05)
})
n
tam <- 15
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam)))
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.05)
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam)))
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.05)
lower <- seq_along(tamanhos) |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.005)
})
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.005)
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.005)
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.005)
})
lower
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.05)
})
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam, mean = 10, sd = 5))) |>
quantile(probs = 0.05)
})
lower
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam, mean = 100, sd = 5))) |>
quantile(probs = 0.05)
})
lower
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam, sd = 10))) |>
quantile(probs = 0.05)
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam, sd = 10))) |>
quantile(probs = 0.05)
})
lower
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam, sd = 1))) |>
quantile(probs = 0.05)
})
lower
tamanhos <- c(
15,
25,
seq(from = 30, to = 100, by = 10),
150,
seq(from = 200, to = 1000, by = 100)
)
n <- 5000
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = 0.05)
})
lower
tibble(tamanhos, lower)
n <- 5000
g <- 0.95
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 - g) / 2)
})
lower
tibble(tamanhos, lower)
n <- 5000
g <- 0.90
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 - g) / 2)
})
tibble(tamanhos, lower)
n <- 5000
g <- 0.90
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 - g) / 2)
})
upper <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 + g) / 2)
})
df <- tibble(tamanhos, lower, upper)
df
n <- 10000
g <- 0.90
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 - g) / 2)
})
upper <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 + g) / 2)
})
df <- tibble(tamanhos, lower, upper)
df
?knitr::kable
#| echo: false
tamanhos <- c(
10, 30, 50, 60, 70, 80, 90, 100,
150, 250, 300, 500, 750, 1000
)
n <- 10000
g <- 0.90
lower <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 - g) / 2)
})
upper <- tamanhos |>
map_dbl(\(tam) {
seq_len(n) |>
map_dbl(~ BowleySkew(rnorm(tam))) |>
quantile(probs = (1 + g) / 2)
})
df <- tibble(tamanhos, lower, upper)
knitr::kable(
df,
col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
caption = "Limite inferior e superior para o coeficiente de Bowley no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com "
)
knitr::kable(
df,
digits = 2,
col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
caption = "Limite inferior e superior para o coeficiente de Bowley no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
align = c("c", "c", "c"),
format.args = list(decimal.mark = ",", big.mark = ".")
)
?skewness
