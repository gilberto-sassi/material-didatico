---
title: "Exploração e visualização de dados"
author: "Gilberto Pereira Sassi"
lang: pt-br
fontsize: 10pt
bibliography: refs.bib
biblio-style: apa
format:
    beamer:
        institute: "Departamento de Estatística\\newline Instituto de Matemática e Estatística"
        theme: Pittsburgh
        colortheme: spruce
        # logo: logo_menor.png
        keep-tex: true
        colorlinks: true
        linkcolor: titulo
        urlcolor: titulo
        filecolor: magenta
        include-in-header: header.tex
        include-before-body: before_body.tex
pdf-engine: pdflatex
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE,
                    fig.align = "center", out.width="50%")
#rmarkdown::find_pandoc(dir = "/home/gilberto/.local/bin", version = "2.13")
library(pacman)
p_load(glue)
p_load(readxl)
p_load(writexl)
p_load(janitor)
p_load(dplyr)
p_load(gt)
p_load(ggthemes)
p_load(statBasics)
p_load(MASS)
p_load(readODS)
p_load(dados)
p_load(patchwork)
p_load(aplpack)
p_load(rlang)
p_load(mvtnorm)
p_load(qqplotr)
p_load(KbMvtSkew)
p_load(ggthemes)
p_load(lvplot)
p_load(scales)
p_load(DescTools)
p_load(tidyverse)


```

# Sobre o curso

## Preparando o ambiente 

* Em casa, você pode usar:
  - [colab.research.google.com/#create=true&language=r](https://colab.research.google.com/#create=true&language=r);
  - [posit.cloud](https://posit.cloud).
* No seu dia-a-dia, recomenda-se instalar o `R` com versão pelo menos `4.1`: [cran.r-project.org](https://cran.r-project.org).
* **IDE** recomendadas: [_RStudio_](https://posit.co/downloads/) e [_VSCode_](https://code.visualstudio.com).
  * Caso você queira usar o [_VSCode_](https://code.visualstudio.com), instale [a extensão da linguagem `R`](https://code.visualstudio.com/docs/languages/r).
* Neste curso, usaremos o _framework_ [**tidyverse**](https://www.tidyverse.org):
  * Instale o framework a partir do repositório CRAN: `install.packages("tidyverse")`
* Outras linguagens interessantes: [`python`](https://www.python.org) e [`julia`](https://julialang.org).
  * [`python`](https://www.python.org): linguagem interpretada de próposito geral, contemporânea do `R`,  simples e fácil de aprender.
  * [`julia`](https://julialang.org): linguagem interpretada para análise de dados, lançada em 2012, promete simplicidade e velocidade.

# A linguagem `R`:\newline\newline\ uma introdução
 
## O começo de tudo 

**O precursor do `R`: `S`.**

* `R` é uma linguagem derivada do `S`.
* `S` foi desenvolvido em `fortran` por **John Chambers** em _1976_ no **Bell Labs**.
* `S` foi desenvolvido para ser um ambiente de análise estatística.
* Filosofia do `S`: permitir que usuários possam analisar dados usando estatística com pouco conhecimento de programação.

**História do `R`**

* Em _1991_, **Ross Ihaka** e **Robert Gentleman** criaram o `R` na **Nova Zelândia**.
* Em _1996_, **Ross** e **Robert** liberam o `R` sob a licença "GNU General License", o que tornou o `R` um software livre.
* Em _1997_, **The Core Group** é criado para melhorar e controlar o código fonte do `R`.

## Porque usar `R` 

* Constante melhoramento e atualização.
* Portabilidade (roda em praticamente todos os sistemas operacionais).
* Grande comunidade de desenvolvedores que adicionam novas capacidades ao R através de pacotes.
* Gráficos de maneira relativamente simples.
* Interatividade.
* Um grande comunidade de usuários (especialmente útil para resolução de problemas).

## Onde estudar fora de aula?

**Livros **

Recomendo principalmente o livro [`R` for Data Science](https://r4ds.had.co.nz).

\vspace{0.5cm}

* **Nível Iniciante:** [R Tutorial na W3Schools](https://www.w3schools.com/r/default.asp).
* **Nível Iniciante:** [Hands-On Programming with `R`](https://rstudio-education.github.io/hopr/).
* **Nível Iniciante:** [`R` for Data Science](https://r4ds.had.co.nz).
* **Nível Intermediário:** [Advanced `R`](https://adv-r.hadley.nz/).

\regrafina

**Livros em português**

* **Nível _cheguei agora aqui_:** [zen do R](https://curso-r.github.io/zen-do-r/index.html).
* **Nível Avançado:** [Advanced `R`](https://adv-r.hadley.nz).
* **Nível Iniciante:** [material.curso-r.com](http://material.curso-r.com/).
* **Nível Iniciante:** [ecoR](http://ecor.ib.usp.br/doku.php).
* **Nível Iniciante:** [analises-ecologicas.com](https://analises-ecologicas.com/).

---

**Plataformas de ensino on-line**

* **Datacamp:** [datacamp.com](https://www.datacamp.com/)
* **Dataquest:** [dataquest.io](https://www.dataquest.io/)

## O que você pode fazer quando estiver em apuros?

* consultar a documentação do `R`: 
```{r}
#| echo: true
#| eval: false
help(mean)
?mean
```

* Peça ajuda a um programador mais experiente.
* Conmsulte [Rstudio community](https://community.rstudio.com/).
* Consulte [pt.stackoverflow.com](https://pt.stackoverflow.com/).
* Use ferramentas de busca como o [google](https://www.google.com.br/) e [duckduckgo.com](https://duckduckgo.com/).

```r
sqrt("Gilberto")
```

* Na ferramenta de busca, pesquise por `Error in sqrt("Gilberto"): non-numeric argument to mathematical function`

## Operações básicas 

**Soma**

```{r}
1 + 1
```

**Substração**

```{r}
2 - 1
```

**Divisão**

```{r}
3 / 2
```

**Potenciação**

```{r}
2^3
```

## Operações básicas\newline Exercício

Qual o resultado das seguintes operações?

1. `5.32 + 7.99`
1. `5.55 - 10`
1. `3.33 * 5.12`
1. `1 / 4.55`
1. `5^1.23`

## Funções na linguagem `R`

**Função:** é uma ação e tem os seguinte componentes na ordem:

* _nome da função_
* _parênteses_
* _argumentos posicionais_
* _argumentos nomeados_

\footnotesize

$$
\overbrace{\texttt{nome\_funcao}}^{\text{\textit{nome da função}}} \overbrace{(}^{\text{\textit{parênteses}}} \overbrace{\texttt{valor1},\quad \texttt{valor2}}^{\text{\textit{argumentos posicionais}}},\quad \overbrace{\texttt{nome1 = valor3},\quad \texttt{nome2 = valor4}}^{\text{\textit{argumentos nomeados}}} \overbrace{)}^{\text{\textit{parênteses}}}
$$

\normalsize

**example:**

```r
read_xlsx('data/raw/casas.xlsx', sheet=1)
```

## Funções na linguagem `R`\newline Exercício

* Obtenha ajuda para `mean` usando a função `help`.
* Calcule o logaritmo de 10 na base 3 usando a função `log`.
* Leia o conjunto de dados `amostra_enem_salvador.xlsx` usando a função `read_xlsx` do pacote `readxl`.

## Estrutura de dados no `R`

* **Tipo de dados:** caracter (`character`), número real (`double`), número inteiro (`integer`), número complexo (`complex`) e lógico (`logical`).
* **Estrutura de dados:** atomic `vector` (a estrutura de dados mais básicA no `R`), `matrix`, `array`, `list` e `data.frame` (`tibble` no `tidyverse`).
* **Estrutura de dados Homogênea:** `vector`, `matrix` e `array`.
* **Estrutura de dados Heterôgenea:** `list` e `data.frame` (`tibble` no `tidyverse`).

## Tipo de dados no `R` 

**Número inteiro**

```{r}
class(1L)
```

**Número real**

```{r}
class(1.2)
```

**Número complexo**

```{r}
class(1 + 1i)
```


## Tipo de dados no `R` 

**Número lógico ou valor booleano**

```{r}
class(TRUE)
```

**Caracter ou *string***

```{r}
class("Gilberto")
```


## Estrutura de dados homogênea

**Vetor**

* Agrupamento de valores de mesmo tipo em um único objeto.
* Criação de vetor: 
  - `c(...)`;
  - `vector('<tipo de dados>', <comprimento do vetor>)`;
  - `seq(from = a, to = b, by = c)`;
  - `seq_along(<vetor>)` - vetor de números inteiros com o mesmo trabalho de `<vetor>`;
  - `seq_len(<número inteiro>)` - vetor de números inteiros com o tamanho `<número inteiro>`;
  - `<número inicial>:<número final>` - sequência de números inteiros entre `<número inicial>` e `<número final>`
* Podemos checar o `tipo de dados` de um vetor com a função `class`.

---

**Vetor de caracteres**

```{r}
nomes  <- c("Gilberto", "Sassi")
class(nomes)
nomes
```

```{r}
texto_vazio <- vector("character", 3)
class(texto_vazio)
texto_vazio
```


## Estrutura de dados homogênea 

**Vetor de números reais**

```{r}
vetor_real  <- c(0.2, 1.35)
class(vetor_real)
vetor_real
```


```{r}
vetor_real <- vector("double", 3)
vetor_real
```

```{r}
vetor_real <- seq(from = 1, to = 3.5, by = 0.5)
vetor_real
```


## Estrutura de dados homogênea 

**Vetor de números inteiros**

```{r}
vetor_inteiro  <- c(1L, 2L)
class(vetor_inteiro)
vetor_inteiro
```

```{r}
vetor_inteiro <- vector("integer", 3)
vetor_inteiro
```

```{r}
vetor_inteiro <- 1:4
vetor_inteiro
```

---


```{r}
vetor_real  <- seq_along(nomes)
class(vetor_real)
vetor_real
```

```{r}
vetor_real <- seq_len(5)
class(vetor_real)
vetor_real
```


## Estrutura de dados homogênea 

**Vetor lógico**

```{r}
vetor_logico  <- c(TRUE, FALSE)
class(vetor_logico)
vetor_logico
```

```{r}
vetor_logico <- vector("logical", 3)
vetor_logico
```

## Estrutura de dados homogênea\newline Exercício

Crie os seguintes vetores:

1. $\begin{pmatrix} 0,1 & 0,2 & 0,3 & 0,4 & 0,5  \end{pmatrix}$
1. $\begin{pmatrix} TRUE & TRUE & FALSE \end{pmatrix}$
1. $\begin{pmatrix} "Marx" & "Engels" & "Lênin" \end{pmatrix}$
1. $\begin{pmatrix} 1 & 2 & 3 \end{pmatrix}$

## Estrutura de dados homogênea

**Operações com vetores númericos (`double`, `integer` e `complex`).**

* Operações básicas (operação, substração, multiplicação e divisão ) realizada em cada elemento do vetor.
* _Slicing_: extrair parte de um vetor (não precisa ser vetor numérico).

**_Slicing_**

```{r}
vetor <- c("a", "b", "c", "d", "e", "f", "g", "h", "i")
# selecionado todos os elementos entre o primeiro e o quinta
vetor[1:5] 
```

**Adição (vetores númericos)**

```{r}
vetor_1 <- 1:5
vetor_2 <- 6:10
vetor_1 + vetor_2
```

## Estrutura de dados homogênea 

\small

**Substração (vetores numéricos)**

```{r}
vetor_1 <- 1:5
vetor_2 <- 6:10
vetor_2 - vetor_1
```

**Multiplicação (vetores numéricos)**

```{r}
vetor_1 <- 1:5
vetor_2 <- 6:10
vetor_2 * vetor_1
```

**Divisão (vetores numéricos)**

```{r}
vetor_1 <- 1:5
vetor_2 <- 6:10
vetor_2 / vetor_1
```

\normalsize

## Estrutura de dados homogênea\newline Exercício

Realize as seguintes operações envolvendo vetores:

1. $\begin{pmatrix} 1 & 2 & 3 \end{pmatrix} + \begin{pmatrix} 0,1 & 0,05 & 0,33 \end{pmatrix}$
1. $\begin{pmatrix} 1 & 2 & 3 \end{pmatrix} - \begin{pmatrix} 0,1 & 0,05 & 0,33 \end{pmatrix}$
1. $\begin{pmatrix} 1 & 2 & 3 \end{pmatrix} * \begin{pmatrix} 0,1 & 0,05 & 0,33 \end{pmatrix}$
1. $\begin{pmatrix} 1 & 2 & 3 \end{pmatrix} / \begin{pmatrix} 0,1 & 0,05 & 0,33 \end{pmatrix}$


## Estrutura de dados homogênea

**Matriz**

* Agrupamento de valores de mesmo tipo em um único objeto de dimensão 2.
* Criação de matriz:
  - `matrix(..., nrow = <integer>, ncol = <integer>, byrow = TRUE)` - preenche a matriz a partir das linhas se `byrow = TRUE`;
  - `diag(<vector>)` - diagonal principal igual a `<vetor>` e outros elementos zero;
  - `rbind()` - especificação das linhas da matriz;
  - `cbind()` - especificação das colunas da matriz.

---

**Matriz de caracteres**

```{r}
matriz_texto <- rbind(c("a", "b"), c("c", "d"))
matriz_texto
```



**Matriz de números reais**

```{r}
matriz_real <- matrix(seq(from = 0, to = 1.5, by = 0.5),
                      nrow = 2, byrow = TRUE)
matriz_real
```

## Estrutura de dados homogênea 

**Matriz de inteiros**

```{r}
matriz_inteiro <- cbind(c(1L, 2L), c(3L, 4L))
matriz_inteiro
```

**Matriz de valores lógicos**

```{r}
matriz_logico <- matrix(c(TRUE, F, F, T), nrow = 2)
matriz_logico
```

## Estrutura de dados homogênea

**Array**

* Agrupamento de valores de mesmo tipo em um único objeto em duas ou mais dimensões.
* Criação de array: `array(..., dim = <vector of integers>)`.

```{r}
#| echo: true
#| eval: false
dados_matriz_1 <- 10:13
dados_matriz_2  <- 14:17
resultado <- array(c(dados_matriz_1, dados_matriz_2),
                  dim = c(2, 2, 2))
resultado
```

---

```{r}
#| echo: false
#| eval: true
dados_matriz_1 <- 10:13
dados_matriz_2  <- 14:17
resultado <- array(c(dados_matriz_1, dados_matriz_2), dim = c(2, 2, 2))
resultado
```


## Estrutura de dados homogênea 

**Operações com matrizes númericas (`double`, `integer` e `complex`).**

* Operações básicas (operação, substração, multiplicação e divisão) realizada em cada elemento das matrizes.
* Outras operações:
  - [Multiplicação de matrizes](https://pt.wikipedia.org/wiki/Produto_de_matrizes);
  - [Inversão de matrizes](https://pt.wikipedia.org/wiki/Matriz_inversa);
  - [Matriz transposta](https://pt.wikipedia.org/wiki/Matriz_transposta);
  - [Determinante](https://pt.wikipedia.org/wiki/Determinante);
  - [Solução de sistema de equações lineares](https://pt.wikipedia.org/wiki/Sistema_de_equações_lineares).

## Operações com matrizes

**Matrizes**

```{r}
matriz_a <- rbind(c(1, 2), c(0, 3))
matriz_b <- matrix(runif(4), ncol = 2)
```

\regrafina

\small

**Soma**

```{r}
matriz_soma <- matriz_a + matriz_b
matriz_soma
```

**Subtração**

```{r}
matriz_menos <- matriz_a - matriz_b
matriz_menos
```

\normalsize

## Operações com matrizes

**Produto de Hadamard**

* Multiplicação de matrizes, elemento por elemento.
* Para detalhes consulte [produto de Hadamard](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)).

```{r}
matriz_hadamard <- matriz_a * matriz_b
matriz_hadamard
```

\regrafina

[**Multiplicação de matrizes**](https://pt.wikipedia.org/wiki/Matriz_inversa)

```{r}
matriz_multiplicacao <- matriz_a %*% matriz_b
matriz_multiplicacao
```

## Operações com matrizes 

\small

[**Matriz inversa**](https://pt.wikipedia.org/wiki/Matriz_inversa)

```{r}
matriz_inversa <- solve(matriz_a)
matriz_inversa
matriz_a %*% matriz_inversa
```


[**Matriz transposta**](https://pt.wikipedia.org/wiki/Matriz_transposta)

```{r}
matriz_transposta <- t(matriz_a)
matriz_transposta
```

\normalsize

## Operações com matrizes 

\small

[**Determinante**](https://pt.wikipedia.org/wiki/Determinante)

```{r}
det(matriz_a)
```

[**Solução de sistema de equações lineares**](https://pt.wikipedia.org/wiki/Sistema_de_equações_lineares)

```{r}
b <- c(1, 2)
solve(matriz_a, b)
```

**Matriz inversa generalizada**

$G$ é a matriz inversa generalizada de $A$ se $A \cdot G \cdot A = A$. Para detalhes vide [matriz inversa generalizada](https://en.wikipedia.org/wiki/Generalized_inverse).

```{r}
p_load(MASS) # ginv é uma função do pacote MASS
ginv(matriz_a)
```

\normalsize

## Operações com matrizes

**Outras operações com matrizes.**

|Operador ou função|Descrição|
|:--------------:|:-----------:|
|`A %o% B`| [produto diádico $A\cdot B^T$](https://pt.wikipedia.org/wiki/Produto_diádico)|
|`crossprod(A, B)`|[$A\cdot B^T$](https://pt.wikipedia.org/wiki/Produto_diádico)|
|`crossprod(A)`|[$A\cdot A^T$](https://pt.wikipedia.org/wiki/Produto_diádico)|
|`diag(x)`|retorna uma matrix diagonal com diagonal igual a `x`|
|`diag(A)`|retorna um vetor com a diagona de $A$|
|`diag(k)`|retorna uma matriz diagona de ordem $k$|

## Estrutura de dados homogênea\newline Exercício

Realize as seguinte operações envolvendo as matrizes:

1. $\begin{pmatrix} 1 & 0\\ 2 & 0,5 \end{pmatrix} + \begin{pmatrix} 0,1 & 0\\ 0 & 0,5 \end{pmatrix}$
1. $\begin{pmatrix} 1 & 0\\ 2 & 0,5 \end{pmatrix} - \begin{pmatrix} 0,1 & 0\\ 0 & 0,5 \end{pmatrix}$
1. Multiplicação de matriz: $\begin{pmatrix} 1 & 0\\ 2 & 0,5 \end{pmatrix} \cdot \begin{pmatrix} 0,1 & 0\\ 0 & 0,5 \end{pmatrix}$ 
1. Divisão elemento a elemento:  $\begin{pmatrix} 1 & 0\\ 2 & 0,5 \end{pmatrix} / \begin{pmatrix} 0,1 & 0\\ 0 & 0,5 \end{pmatrix}$
1. Resolva o seguinte sistema de equações: $\begin{cases} x + 2 y = 21 \\ x - 2y = 1 \end{cases}$.
1. Encontre a matriz inversa de $\begin{pmatrix} 1 & 2 \\ 1 & -2 \end{pmatrix}$.


## Estrutura de Dados Heterogênea 

**Lista**

* Agrupamento de valores de tipos diversos e estrutura de dados 
* Criação de listas: `list(...)` e `vector("list", <comprimento da lista>)`

```{r}
#| echo: true
#| eval: false
lista_info <- list(pedido_id = 8001406,
          nome = "Fulano",
          sobrenome = "de Tal",
          cpf = "12345678900",
          itens = list(list(descricao = "Ferrari",
                            frete = 0,
                            valor = 500000),
                        list(descricao = "Dolly", frete = 1.5,
                              valor = 3.90)))
lista_info
```

---

\scriptsize

```{r}
#| echo: false
#| eval: true
lista_info <- list(pedido_id = 8001406,
          nome = "Fulano",
          sobrenome = "de Tal",
          cpf = "12345678900",
          itens = list(list(descricao = "Ferrari",
                            frete = 0,
                            valor = 500000),
                      list(descricao = "Dolly", frete = 1.5, valor = 3.90)))
lista_info
```

\normalsize

## Estrutura de dados heterogênea\newline Exercício

Crie uma lista, chamada `informacoes_pessoais` com os seguintes campos:

* `nome`: seu nome
* `idade`: sua idade
* `informacao_profissional`: uma lista com os seguintes campos:
  * `matricula`: escolaridade
  * `origem`: variável qualitativa com a sua cidade de origem.
* `matriz`: inclua uma matriz de números reais de dimensão $2\times 2$

## Operação com listas

* _slicing_ - `[]` - extrai parte da lista (valor retornado é uma lista).
* Acessando $k$-ésimo valor da lista: `lista[[k]]`.
* Acessando um valor da lista pela chave (nome do campo): `lista$cpf`.
* Concatenação de listas: `c()`.

\regrafina

**_Slicing_**

```{r}
lista_info[c(2, 4)]
```

**Acessando elemento pela posição**

```{r}
lista_info[[2]]
```

---

**Acessando elemento pela chave**

```{r}
lista_info$nome
```

**Concatenação de listas**

```{r}
lista_1 <- list(1, 2)
lista_2 <- list("Gilberto", "Sassi")
lista_concatenada <- c(lista_1, lista_2)
lista_concatenada
```

## Estrutura de dados heterogênea\newline Exercício

Recupe e imprima as seguintes informações da lista `informacoes_pessoais`:

* os três primeiros campos de `informacoes_pessoais`
* os nomes dos campos de `informacoes_pessoais`
* campo `nome` de `informacoes_pessoais`
* o terceiro campo de `informacoes_pessoais`


## Estrutura de Dados Heterogênea 

**Tidy data**

* Dados em formato de tabela.
* Cada coluna é uma variável e cada linha é uma observação.

\regrafina

**`tibble` (data frame)**

* Estrutura de dados tabular.
* Assumimos que os dados estão **tidy**.
* Criação de `tibble`: `tibble(...)` e `tribble(....)`.
* `glimpse` mostra as informações do `tibble`.

---

```{r}
p_load(tidyverse) # carregando o framework tidyverse
data_frame <- tibble(
  nome = c("Marx", "Engels", "Rosa", "Lênin", "Olga Benário"),
  idade = c(22, 23, 21, 24, 30)
)
glimpse(data_frame)
```

## Valores especiais em `R` 

|Valores especiais|Descrição|Função para identificar|
|:-------------|:---------------|--------------------:|
|`NA`|Valor faltante.|`is.na()`|
|`NaN`|Resultado do cálculo indefinido.|`is.nan()`|
|`Inf`|Valor que excede o valor máximo que sua máquina aguenta.|`is.inf()`|
|`NULL`|Valor indefinido de expressões e funções (diferente de `NaN` e `NA`)|`is.null()`|


## Operações básicas em um `tibble`

|Função|Descrição|
|:---------|:------------|
|`head()`|Mostra as primeiras linhas de um `tibble`|
|`tail()`|Mostra as últimas linhas de um `tibble`|
|`glimpse()`|Impressão de informações básicas dos dados|
|`add_case()`|Adiciona uma nova observação|
|`add_row()`|Adiciona uma nova observação|

---

```{r}
head(data_frame, n=2)
```

```{r}
tail(data_frame, n=2)
```


## Estrutura de dados heterogênea\newline Exercício

Realize as seguintes operações no _dataset_ `iris` (disponível no `R`):

* imprima um resumo sobre o _dataset_ `iris`.
* pegue as 5 primeiras linhas de `iris`.
* pegue as 5 últimas linhas de `iris`.
* crie _na mão_ o seguinte conjunto de dados:

```{r}
#| echo: false
df_equipe <- tibble(
  nomes = c("Fidel Castro", "Ernesto 'Che' Guevara", "Célia Sánchez"),
  origem = c("Cuba", "Cuba", "Cuba")
)
knitr::kable(df_equipe)
```

# Organização é fundamental

## Guia de estilo no `R`

O nome de um objeto precisa ter um _significado_. 

O nome deve indicar e deixar claro o que este objeto é ou faz.

* Use a convenção do `R`:
  * Use apenas letras minúsculas, números e _underscore_ (comece sempre com letras minúsculas).
  * Nomes de objetos precisam ser substantivos e precisam descrever o que este objeto é ou faz (seja conciso, direto e significativo).
  * Evite ao máximo os nomes que já são usados ( _buit-in_ ) do `R`.Por exemplo: `c`.
  * Coloque espaço depois da vírgula.
  * Não coloque espaço antes nem depois de parênteses. Exceção: Coloque um espaço `()` antes e depois de `if`, `for` ou `while`, e coloque um espaço depois de `()`.
  * Coloque espaço entre operadores básicos: `+`, `-`, `*`, `==` e outros. Exceção: `^`.

## Estrutura de diretórios

Mantenha uma estrutura (organização) consistente de diretórios em seus projetos.

* Sugestão de estrutura:
  - `dados`: diretório para armazenar seus conjuntos de dados.
    + `brutos`: dados brutos.
    + `processados`: dados processados.
  - `scripts`: código fonte do seu projeto.
  - `figuras`: figuras criadas no seu projeto.
  - `output`: outros arquivos que não são figuras.
  - `legado`: arquivos da versão anterior do projeto.
  - `notas`: notas de reuniões e afins.
  - `relatorio` (ou `artigos`): documento final de seu projeto.
  - `documentos`: livros, artigos e qualquer coisa que são referências em seu projeto.  

Para mais detalhes, consulte esse guia do [curso-r](https://curso-r.com): [diretórios e `.Rproj`](https://curso-r.github.io/zen-do-r/rproj-dir.html).

# Importação e exportação de dados

## Lendo dados no `R` 

\normalsize

**Leitura de arquivos no formato `xlsx` ou `xls`**

* **Pacote:** `readxl`
* Parêmetros das funções `read_xls` (arquivos `.xls`) e `read_xlsx` (arquivos `.xlsx`):
  - `path`: caminho até o arquivo.
  - `sheet`: especifica a planilha do arquivo que será lida.
  - `range`: especifica uma área de uma planilha para leitura. Por exemplo: `B3:E15`.
  - `col_names`: Argumento lógico com valor padrão igual a `TRUE`. Indica se a primeira linha tem o nome das variáveis.
  
Para mais detalhes, consulte a documentação: [documentação de `read_xl`](https://readxl.tidyverse.org).

## Lendo dados no `R` 

**Leitura de arquivos no formato `xlsx` ou `xls`**

\small

```{r}
p_load(tidyverse)
p_load(readxl)
dados_iris <- read_xlsx("dados/brutos/iris.xlsx")
dados_iris <- clean_names(dados_iris)

glimpse(dados_iris)
```

\normalsize

## Lendo dados no `R`\newline Exercício

Leia o _dataset_ `dados_leitura.xlsx` usando o pacote `readxl`. 

## Lendo dados no `R` 

\small

**As formatações dos arquivos `csv`**

* `csv`: _comma separated values_ (valores separados por coluna). O _separador_ varia em diferentes sistemas de medidas.

\regrafina

* No sistema métrico:
  * As casas decimais são separadas por `,`
  * O agrupamento de milhar é marcada por `.`
  * As colunas dos arquivos de texto são separadas por `;`

\regrafina

* No sistema imperial inglês (UK e USA):
  * As casas decimais são separadas por `.`
  * O agrupamento de milhar é marcada por `,`
  * As colunas dos arquivos de texto são separadas por `,`

***Preste atenção em como o seus dados estão armazenados!***

\normalsize

---

**Leitura de arquivos no formato `csv`**


* **Pacote:** `readr` do `tidyverse` (instale com o comando `install.packages('readr')`).
* Parêmetros das funções `read_csv` (sistema imperial inglês) e `read_csv2` (sistema métrico):
  * `path`: caminho até o arquivo.

Para mais detalhes, consulte a documentação oficial do _tidyverse_: [documentação de `read_r`](https://readr.tidyverse.org).

## Lendo dados no `R`

**Leitura de arquivos no formato `csv`**

\scriptsize

```{r, message=FALSE}
dados_mtcarros <- read_csv2("dados/brutos/mtcarros.csv")
dados_mtcarros <- clean_names(dados_mtcarros)
glimpse(dados_mtcarros)
```

\normalsize

## Lendo dados no `R`\newline Exercício

Leia o _dataset_ `dados_leitura.csv` usando o pacote `readr`. 

## Lendo dados no `R` 

**Leitura de arquivos no formato `ods`**

* **Pacote:** `readODS`  (instale com o comando `install.packages('readODS')`).
* Parêmetros das funções `read_ods`:
* `path`: caminho até o arquivo.
  * `sheet`: especifica a planilha do arquivo que será lida.
  * `range`: especifica uma área de uma planilha para leitura. Por exemplo: `B3:E15`.
  * `col_names`: Argumento lógico com valor padrão igual a `TRUE`. Indica se a primeira linha tem o nome das variáveis.

Para mais detalhes, consulte a documentação do _readODS_: [documentação de `readODS`](https://github.com/chainsawriot/readODS).

## Lendo dados no `R` 

**Leitura de arquivos no formato `ods`**

```{r}
p_load(readODS)
dados_dentes <- read_ods("dados/brutos/crescimento_dentes.ods")
dados_dentes <- clean_names(dados_dentes)

glimpse(dados_dentes)
```

## Lendo dados no `R`\newline Exercício

Leia o _dataset_ `dados_leitura.ods` usando o pacote `readODS`. 

## Exportando dados no `R`

\small

**Salvar no formato `.csv` (sistema métrico)**

`write_csv2` é parte do pacote `readr`.

```{r}
#| eval: false
write_csv2(dados_dentes, file = "dados/processados/nome.csv")
```

\rule{\textwidth}{0.5pt}

**Salvar no formato `.xlsx` **

`write_xlsx` é parte do pacote `writexl`.

```{r}
#| eval: false
write_xlsx(dados_dentes, path = "dados/processados/nome.xlsx")
```

\rule{\textwidth}{0.5pt}

**Salvar no formato `ods`**

`write_ods` é parte do pacote `readODS`.

```{r}
#| eval: false
write_ods(dados_toothgrowth, path = "dados/processados/nome.ods")
```

\normalsize

## Salvando dados no `R`\newline Exercício

1. Salve o objeto `milhas` do pacote `dados` como `milhas.ods` na pasta `output` do seu projeto.
1. Salve o objeto `diamante` do pacote `dados` como `diamante.csv` na pasta `output` do seu projeto.
1. Salve o objeto `velho_fiel` do pacote `dados` como `velho_fiel.xlsx` na pasta `output` do seu projeto.

# O operador pipe\newline\ `|>`

## `|>` 

 O valor resultante da expressão do lado esquerdo vira primeiro argumento da função do lado direito. 

 **Principal vantagem:** simplifica a leitura e a documentação de funções compostas.

 \regrafina

Executar

```r
f(x, y)
```

é exatamente a mesma coisa que executar

```r
x |> f(y)
```

---

```r
log(sqrt(sum(x^2)))
```

é exatamente a mesma coisa que executar

```r
x^2 |> sum() |> sqrt() |> log()
```


## `|>` \newline _Fazendo_ um bolo

Exemplo adaptado de [6.1 O operador pipe](https://livro.curso-r.com/6-1-o-operador-pipe.html).

\regrafina

Para cozinhar o bolo precisamos usar as seguintes funções:

* `acrescente(lugar, algo)`
* `misture(algo)`
* `asse(algo)`

## `|>` \newline _Fazendo_ um bolo



* Passo 1:
```r
acrescente(
  "tigela vazia",
  "farinha"
)
```
* Passo2:
```r
acrescente(
  acrescente(
    "tigela vazia",
    "farinha"
  ),
  "ovos"
)
```

---

* Passo3:
```r
acrescente(
  acrescente(
    acrescente(
      "tigela vazia",
      "farinha"
    ),
    "ovos"
  ),
  "leite"
)
```

---

* Passo4:
```r
acrescente(
  acrescente(
    acrescente(
      acrescente(
        "tigela vazia",
        "farinha"
      ),
      "ovos"
    ),
    "leite"
  ),
  "fermento"
)
```

---

* Passo 5:
```r
misture(
  acrescente(
    acrescente(
      acrescente(
        acrescente(
          "tigela vazia",
          "farinha"
        ),
        "ovos"
      ),
      "leite"
    ),
    "fermento"
  )
)
```

---

* Passo 6:
```r
asse(
  misture(
    acrescente(
      acrescente(
        acrescente(
          acrescente(
            "tigela vazia",
            "farinha"
          ),
          "ovos"
        ),
        "leite"
      ),
      "fermento"
    )
  )
)
```

---

Usando o operador `|>`.

\vspace{0.5cm}

```r
acrescente("tigela vazia", "farinha") |>
  acrescente("ovos") |>
  acrescente("leite") |>
  acrescente("fermento") |>
  misture() |>
  asse()
```

# Estatística descritiva

## Estatística Descritiva no `R`\newline Conceitos básicos


* **População**: todos os elementos ou indivíduos alvo do estudo.
* **Amostra**: parte da população.
* **Parâmetro:** característica numérica da população. Usamos letras gregas para denotar parâmetros populacionais.
* **Estatística:** função ou _cálculo_ da amostra
* **Estimativa:** característica numérica da amostra, obtida da estatística computada na amostra. Em geral, usamos uma estimativa para estimar o parâmetro populacional.
* **Variável:** _característica mensurável comum a todos os elementos da população._ 
  * Usamos letras maiúsculas do alfabeto latino para representar uma variável.
  * Usamos letras minúsculas do alfabeto latino para representar o valor observado da variável em um elemento da amostra. 

## Estatística Descritiva no `R`\newline Conceitos básicos

**Exemplo**

* **População**: todos os eleitores nas eleições gerais de 2022.
* **Amostra**: 3.500 pessoas abordadas pelo `datafolha`.
* **Variável:** candidato a presidente de cada pessoa.
* **Parâmetro:** porcentagem de pessoas que escolhem Lula como presidente entre todos os eleitores.
* **Estatística:** porcentagem de pessoas que escolhem o lula
* **Estimativa:** porcentagem de pessoas que escolhem Lula como presidente entre todos os eleitores da amostra de 3.500 pessoas entrevistas pelo datafolha.

## Classificação de variáveis

\tiny

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[node distance = 15em, scale=0.5]
  \tikzstyle{decision} = [diamond, draw, fill=blue!20, text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
  \tikzstyle{block} = [rectangle, draw, fill=blue!20, text width=5em, text centered, rounded corners, minimum height=4em]
  \tikzstyle{line} = [draw, -latex]
  \tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm, minimum height=2em]
  \node [block] (variavel) {Variável};
  \node [block, left of=variavel, text width=12em] (qualitativa) {\textbf{Variável qualitativa}\newline \textit{valores categóricos (texto)}};
  \node [block, right of=variavel, text width=10em] (quantitativa) {\textbf{Variável quantitativa}\newline \textit{valores numéricos}};
  \node [block, below of=qualitativa, left of=qualitativa, text width=6em, node distance=7.5em] (ordinal) {\textbf{Ordinal}\newline\textit{Exemplo}\newline Escolaridade};
  \node [block, below of=qualitativa, right of=qualitativa, text width=4em, node distance=7.5em] (nominal) {\textbf{Nominal}\newline\textit{Exemplo}\newline Gênero};
  \node [block, below of=quantitativa, left of=quantitativa, text width=8em, node distance=7.5em] (discreta) {\textbf{Discreta}\newline\textit{Exemplo}\newline Número de filhos};
  \node [block, below of=quantitativa, right of=quantitativa, text width=4em, node distance=7.5em] (continua) {\textbf{Contínua}\newline\textit{Exemplo}\newline Salário};
  \path [line] (variavel) -- (qualitativa);
  \path [line] (variavel) -- (quantitativa);
  \path [line] (quantitativa) -- (discreta);
  \path [line] (quantitativa) -- (continua);
  \path [line] (qualitativa) -- (ordinal);
  \path [line] (qualitativa) -- (nominal);
\end{tikzpicture}
\caption{Classificação de variáveis.}
\end{figure}

\normalsize

# Tabela

## Tabela de frequência\newline Variável qualitativa 

A primeira coisa que fazemos é contar! 

|$X$|frequência|frequência relativa|porcentagem|
|:---:|:---:|:---:|:---:|
|$B_1$|$n_1$|$f_1$|$100 \cdot f_1\%$|
|$B_2$|$n_2$|$f_2$|$100 \cdot f_2\%$|
|$\vdots$|$\vdots$|$\vdots$|$\vdots$|
|$B_k$|$n_k$|$f_k$|$100 \cdot f_k\%$|
|Total|$n$|$1$|$100\%$|

Em que $n$ é o tamanho da amostra.

## Tabela de distribuição de frequências\newline Variável qualitativa

* **Pacote:** `janitor`.
* `tabyl`: cria a tabela de distribuição de frequências e tem os seguintes parâmetros:
  * `dat`: _data frame_ ou vetor com os valores da variável que desejamos tabular.
  * `var1`: nome da primeira variável.
  * `var2`: nome da segunda variável (opcional).
* `adorn_totals`: adiciona uma linha com os totais de cada coluna
* `adorn_pct_formatting`: acrescenta o sinal de porcentagem e tem o seguinte parâmetro:
  * `digits`: o número de casas decimais depois da vírgula
* `rename` (do pacote `dplyr`) muda os nomes das colunas para português no seguinte formato:
  * `"novo nome" = "velho nome"`

Para mais detalhes, consulte a documentação oficial do _janitor_: [documentação de `tabyl`](https://cran.r-project.org/web/packages/janitor/janitor.pdf).

## Tabela de distribuição de frequências\newline Variável qualitativa

```{r}
dados_iris <- read_xlsx("dados/brutos/iris.xlsx")
tab <- tabyl(dados_iris, especies)  |>
  adorn_totals()  |>
  adorn_pct_formatting(digits = 2) |>
  rename(
    "Espécies" = especies, "Frequência" = n,
    "Porcentagem" = percent
  )
tab
```

## Tabela de distribuição de frequências\newline Variável qualitativa\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`, construa a tabela de distribuição de frequências para as seguintes variáveis:

* `tp_sexo`: gênero que a pessoa se identifica (segundo classificação usada pelo IBGE)
* `tp_cor_raca`: raça (segundo classificação usada pelo IBGE)

## Tabela de distribuição de frequências\newline Variável quantitativa discreta

Muito semelhante a tabela de distribuição de frequência para variáveis qualitativas.

|$X$|frequência|frequência relativa|porcentagem|
|:---:|:---:|:---:|:---:|
|$x_1$|$n_1$|$f_1$|$100 \cdot f_1\%$|
|$x_2$|$n_2$|$f_2$|$100 \cdot f_2\%$|
|$\vdots$|$\vdots$|$\vdots$|$\vdots$|
|$x_k$|$n_k$|$f_k$|$100 \cdot f_k\%$|
|Total|$n$|$1$|$100\%$|

Em que $n$ é o tamanho da amostra e $\{x_1, \dots, x_k\}$ são os números que são valores únicos de $X$ na amostra.

## Tabela de distribuição de frequências\newline Variável quantitativa discreta

```{r}
dados_mtcarros <- read_csv2("dados/brutos/mtcarros.csv")
tab <- tabyl(dados_mtcarros, carburadores)  |>
  adorn_totals()  |>
  adorn_pct_formatting(digits = 2) |>
  rename(
    "Carburadores" = carburadores, "Frequência" = n,
    "Porcentagem" = percent
  )
tab
```

## Tabela de distribuição de frequências\newline Variável quantitativa discreta\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`, construa a tabela de distribuição de frequências para a variável `q005`: número de pessoas que moram na casa da(o) candidata(o).

## Tabela de frequência\newline Variável quantitativa contínua

`X`: variável quantitativa contínua

|`X`|Frequência|Frequência relativa|Porcentagem|
|:-----:|:-------:|:-------:|:---------:|
|$[l_0, l_1)$| $n_1$|$f_1 = \frac{n_1}{n_1 + \dots + n_k}$|$p_1 = f_1 \cdot 100$|
|$[l_1, l_2)$| $n_2$|$f_2 = \frac{n_2}{n_1 + \dots + n_k}$|$p_2 = f_2 \cdot 100$|
|$\vdots$| $\vdots$|$\vdots$|$\vdots$|
|$[l_{k-1}, l_k]$| $n_k$|$f_k = \frac{n_k}{n_1 + \dots + n_k}$|$p_k = f_k \cdot 100$|
Table: Tabela de frequências para a variável quantitativa contínua.

-----

* $\text{menor valor de }X = l_0 \leq l_1 \leq \cdots \leq l_{k-1} \leq l_k = \text{maior valor de }X$
* $n_i$ é número de valores de `X` entre $l_{i-1}$ e $l_i$
* $l_0, l_1, \dots, l_k$ quebram o suporte da variável `X` (_breakpoints_).
* $l_0, l_1, \cdots, l_k$ são escolhidos de acordo com a teoria por trás da análise de dados

**Recomendações:**

* use $l_0, l_1, \cdots, l_k$ igualmente espaçados
* e use a [regra de Sturges](https://onlinelibrary.wiley.com/doi/10.1002/wics.35) para determinar o valor de $k$:
  * $k = 1 + \log2(n)$ onde $n$ é tamanho da amostra
  * Se $1 + \log2(n)$ não é um número inteiro, usamos $k = \lceil 1 + \log2(n) \rceil$.

## Tabela de frequência\newline Variável quantitativa contínua

Primeiro agrupamos os valores em faixas usando a regra de Sturges.

\regrafina

Usamos a função `cut`, com os seguintes argumentos:

* `breaks` - número de intervalos ou os limites dos intervalos;
* `include.lowest` - se `TRUE` inclue o valor à esquerda no intervalo;
* `right` - se `TRUE` inclue o valor à direita no intervalo.

\regrafina

Usamos a função `mutate` para adicionar uma nova coluna em um `tibble`, com os seguintes argumentos:

* `.data` - `tibble` para adicionar uma nova coluna;
* `<nome da variavel> = <vetor>` - adicione uma ou mais colunas separadas por vírgula.

---

\small

```{r}
k <- ceiling(1 + log(nrow(dados_iris)))
dados_iris2 <- mutate(
  dados_iris,
  comprimento_sepala_int = cut(
    comprimento_sepala,
    breaks = k,
    include.lowest = TRUE,
    right = FALSE
  )
)
glimpse(dados_iris2)
```

\normalsize

## Tabela de frequência\newline Variável quantitativa contínua

Agora podemos contar a frequência de cada intervalo.

```{r}
#| eval: false
tabyl(dados_iris2, comprimento_sepala_int) |>
  adorn_totals() |>
  adorn_pct_formatting(digits = 2) |>
  rename(
    "Comprimento de sépala" = comprimento_sepala_int,
    "Frequência absoluta" = n,
    "Porcentagem" = percent
  )
```

---

```{r}
#| echo: false
tabyl(dados_iris2, comprimento_sepala_int) |>
  adorn_totals() |>
  adorn_pct_formatting(digits = 2) |>
  rename(
    "Comprimento de sépala" = comprimento_sepala_int,
    "Frequência absoluta" = n,
    "Porcentagem" = percent
  )
```

## Tabela de frequência\newline Variável quantitativa contínua\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`, construa as seguintes tabelas de distribuição de frequências:

* `nu_nota_mt` (nota da prova em matemática): $l_0, l_1, \dots, l_k$ são igualmente espaços com $l_k - l_{k-1}=100$
* `nu_nota_cn` (nota da prova de ciências humanas): use a regra de Sturges

# Gráficos

## Gráficos usando `ggplot2`

* **Pacote:** `ggplot2`.
* Permite gráficos personalizados com uma sintaxe simples e rápida, e iterativa _por camadas_.
* Começamos com um camada com os dados `ggplot(dados)`, e vamos adicionando as camadas de anotações, e sumários estatísticos.
* Usa a _gramática de gráficos_ proposta por Leland Wilkinson: [Grammar of Graphics](https://www.springer.com/gp/book/9780387245447).
* Ideia desta gramática: delinear os atributos estéticos das figuras geométricas (incluindo transformações nos dados e mudança no sistema de coordenadas).

Para mais detalhes, você pode consultar [`ggplot2`: elegant graphics for data analysis](https://ggplot2-book.org) e [documentação do `ggplot2`](https://ggplot2.tidyverse.org).

## Gráficos usando `ggplot2`

**Estrutura básica de `ggplot2`**

```r
ggplot(data = <data possible tibble>) +
  <Geom functions>(mapping = aes(<MAPPINGS>)) +
  <outras camadas>
```

Você pode usar diversos temas e extensões que a comunidade cria e criou para melhorar a aparência e facilitar a construção de `ggplot2`.

Lista com extensões do `ggplot2`: [extensões do `ggplot2`](https://exts.ggplot2.tidyverse.org/gallery/).

\regrafina

Indicação de extensões:

* Temas adicionais para o pacote `ggplot2`: [`ggthemes`](https://github.com/jrnold/ggthemes).
* Gráfico de matriz de correlação: [`ggcorrplot`](https://rpkgs.datanovia.com/ggcorrplot/).
* Gráfico quantil-quantil: [`qqplotr`](https://github.com/aloy/qqplotr).

## Gráficos usando `ggplot2`

**Gráfico de barras no `ggplot2`**

* **função:** `geom_bar()`. Para porcentagem: `geom_bar(x = <variável no eixo x>, y = after_stat(prop * 100))`.
* Argumentos adicionais:
  * **`fill`**: mudar a cor do preenchimento das figuras geométricas.
  * **`color`**: mudar a cor da figura geométrica.
* Rótulos dos eixos
  * **Mudar os rótulos:** `labs(x = <rótulo do eixo x>, y = <rótulo do eixo y>)`.
  * **Trocar o eixo-x pelo eixo-y:** `coord_flip()`.

## Gráfico de barras\newline Variável qualitativa

Gráfico de barras para a variável qualitativa `especies` do conjunto de dados `iris.xlsx`.

```{r}
ggplot(dados_iris) +
  geom_bar(mapping = aes(especies), fill = "blue") +
  labs(x = "Espécies", y = "Frequência") +
  theme_minimal()
```

## Gráfico de barras\newline Variável qualitativa\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`, construa o gráfico de barras para as seguintes variáveis:

* `tp_sexo`: gênero que a pessoa se identifica (segundo classificação do IBGE);
* `tp_cor_raca`: raça autodeclarada (segundo classificação do IBGE).

## Tabela de distribuição de frequências\newline Variável quantitativa discreta

De maneira similar, podemos contar quantas vezes cada valor de uma variável quantitativa discreta foi amostrado.

|$X$|frequência|frequência relativa|porcentagem|
|:---:|:--:|:--:|:--:|
|$x_1$|$n_1$|$f_1$|$100\cdot f_1 \%$|
|$x_2$|$n_2$|$f_2$|$100\cdot f_2 \%$|
|$x_3$|$n_3$|$f_3$|$100\cdot f_3 \%$|
|$\vdots$|$\vdots$|$\vdots$|$\vdots$|
|$x_k$|$n_k$|$f_k$|$100\cdot f_k \%$|
|Total|$n$|$1$|$100 \%$|

Em que $n$ é o tamanho da amostra.

## Tabela de distribuição de frequências\newline Variável quantitativa discreta

Vamos construir a tabela de distribuição de frequências para a variável quantitativa discreta `carburadores` do conjunto de dados `mtcarros`.

```{r}
#| eval: false
tab <- tabyl(dados_mtcarros, carburadores) |>
  adorn_totals() |>
  adorn_pct_formatting(digits = 2) |>
  rename(
    "Número de carburadores" = carburadores,
    "Frequência (absoluta)" = n,
    "Porcentagem" = percent
  )
tab
```

----

\small

```{r}
#| echo: false
tab <- tabyl(dados_mtcarros, carburadores) |>
  adorn_totals() |>
  adorn_pct_formatting(digits = 2) |>
  rename(
    "Número de carburadores" = carburadores,
    "Frequência (absoluta)" = n,
    "Porcentagem" = percent
  )
tab
```

\normalsize

## Gráfico de barras\newline Variável quantitativa discreta

\small

Gráfico de barras para a variável quantitativa discreta `carburadores` do conjunto de dados `mtcarros.csv`.

* `after_stat(prop)` retorna a _frequência relativa_ ou _proporção_ de um valor (ou categoria) de uma variável.
* `after_stat(count)` retorna a _frequência absoluta_  de um valor (ou categoria) de uma variável.

```{r}
#| eval: false
ggplot(dados_mtcarros) +
  geom_bar(
    mapping = aes(carburadores, after_stat(100 * prop)),
    fill = "#002f81"
  ) +
  labs(x = "Número de carburadores", y = "Porcentagem") +
  theme_minimal()
```

\normalsize

---

```{r}
#| echo: false
#| out.width: 100%
ggplot(dados_mtcarros) +
  geom_bar(
    mapping = aes(carburadores, after_stat(100 * prop)),
    fill = "#002f81"
  ) +
  labs(x = "Número de carburadores", y = "Porcentagem") +
  theme_minimal()
```

## Gráfico de barras\newline Variável quantitativa discreta\newline Exercício

* Para a variável `q005` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o gráfico de barras onde o eixo y é a frequência absoluta.
* Para a variável `q005` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o gráfico de barras onde o eixo y é a frequência relativa.
* Para a variável `q005` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o gráfico de barras onde o eixo y é a porcentagem.

## Histograma

Para variávieis quantitativas contínuas, geralmente não construímos gráficos de barras, e sim uma figura geométrica chamada de _histograma_.

* O histograma é um gráfico de barras contíguas em que a área de cada barra é
igual à frequência relativa.
* Cada faixa de valor $[l_{i-1}, l_{i}), i=1, \dots, n,$ será representada por um barra com área $f_i, i=1, \dots, n$.
* Como cada barra terá área igual a $f_i$ e base $l_i - l_{i-1}$, e a altura de cada barra será $\frac{f_i}{l_i - l_{i-1}}$.
* $\frac{f_i}{l_i - l_{i-1}}$ é denominada de densidade de frequência.
* Podemos usar os seguintes parâmetros (**obrigatório o uso de apenas um deles**):
  * `bins`: número de intervalos no histograma (usando, por exemplo, a regra de Sturges)
  * `binwidth`: tamanho (ou largura) dos intervalos
  * `breaks`: os limites de cada intervalo

## Histograma

\begin{figure}
\centering
\caption{Representação de uma única barra de um histograma.}
\begin{tikzpicture}
  \filldraw[blue!30] (1,0) rectangle (3,2);
  \draw[black] (1,0) rectangle (3,2);
  \node at (2,1) {\tiny$\frac{f_i}{l_i - l_{i-1}}\cdot l_i - l_{i-1}$};
  \draw[->] (0,0) -- (0,3);
  \draw[->] (0,0) -- (4,0);
  \node[right] at (4,0) {Variável contínua};
  \node[above] at (0,3) {Denside de frequência};
  \draw[decorate,decoration={brace,mirror}] (3,0) -- (3,2);
  \node[right] at (3,1) {$\frac{f_i}{l_i - l_{i-1}}$};
  \draw[decorate,decoration={brace,mirror}] (1,0) -- (3,0);
  \node[below] at (2,0) {$l_i - l_{i-1}$};
\end{tikzpicture}
\end{figure}

## Histograma

```{r}
#| eval: false
ggplot(dados_iris) +
  geom_histogram(
    aes(x = comprimento_sepala, y = after_stat(density)),
    bins = k,
    fill = "#002f81"
  ) +
  theme_minimal() +
  labs(
    x = "Comprimento de Sépala",
    y = "Densidade de Frequência"
  )
```

---

```{r}
#| echo: false
#| out.width: 100%
ggplot(dados_iris) +
  geom_histogram(
    aes(x = comprimento_sepala, y = after_stat(density)),
    bins = k,
    fill = "#002f81"
  ) +
  theme_minimal() +
  labs(
    x = "Comprimento de Sépala",
    y = "Densidade de Frequência"
  )
```

## Histograma\newline Exercício

* Para a variável `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o histograma onde os intervalos tem o mesmo tamanho igual a 100.
* Para a variável `nu_nota_cn` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o histograma usando a regra de Sturge.

## Histograma\newline Linha de densidade

* Podemos adicionar uma linha que acompanha o formato do histograma.
* Chamamos esta linha de densidade.
* Podemos fazer isso com a função `geom_density` do pacote `ggplot2`.

```{r}
#| eval: false
#| out.width: 100%
ggplot(dados_iris, aes(x = comprimento_sepala,
                      y = after_stat(density))) +
  geom_histogram(
    bins = k,
    fill = "#002f81"
  ) +
  geom_density(size = 2, color = "red") +
  theme_minimal() +
  labs(
    x = "Comprimento de Sépala",
    y = "Densidade de Frequência"
  )
```

---

```{r}
#| echo: false
#| out.width: 100%
ggplot(dados_iris, aes(x = comprimento_sepala, y = after_stat(density))) +
  geom_histogram(
    bins = k,
    fill = "#002f81"
  ) +
  geom_density(size = 2, color = "red") +
  theme_minimal() +
  labs(
    x = "Comprimento de Sépala",
    y = "Densidade de Frequência"
  )
```

## Histograma\newline Exercício

* Para a variável `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o histograma onde os intervalos tem o mesmo tamanho igual a 100. Adicione a curva de densidade ao histograma.
* Para a variável `nu_nota_cn` do conjunto de dados `amostra_enem_salvador.xlsx`, construa o histograma usando a regra de Sturge. Adicione a curva de densidade ao histograma.


# Medidas de resumo

## Medidas resumo\newline Variável quantitativa

\small

A ideia é encontrar um ou alguns valores que sintetizem todos os valores.

\regrafina

**Medidas de posição (tendência central)**

A ideia é encontrar um valor que representa _bem_ todos os valores.

* **Média:** $\overline{x} = \dfrac{x_1+\cdots+x_n}{n}$.
* **Mediana:** valor que divide a sequência ordenada de valores em duas partes iguais.
  - Ordene os valores do menor ao maior;
  - Valor que divide os valores entre os 50% menores e os 50% maoires:
    + $50\%$ dos valores $x_i$ satisfazem: $x_i \leq \text{Mediana}$;
    + $50\%$ dos valores $x_i$ satisfazem: $x_i \geq \text{Mediana}$.

## Medidas resumo\newline Variável quantitativa

\begin{figure}
  \centering
  \caption{Representação gráfica para nota em matemática, português, ciências naturais e ciências humanas.}
  \label{fig:dispersao}
   \begin{tikzpicture}[scale=0.7]
    \draw[->] (-1,0) -- (11,0);
    \node[right] at (11,0) {\scriptsize Nota em matemática.};
    \foreach \i in {1,2,3,4,5,6,7,8,9} \filldraw[black] (\i,0) circle (0.025cm);
    \foreach \i in {1,2,3,4,5,6,7,8,9} \node[below] at (\i,0) {\i};
    \foreach \i in {3,4,5,6,7} \filldraw[blue] (\i,0.2) circle (0.035cm);
    \draw[->] (-1,1) -- (11,1);
    \node[right] at (11,1) {\scriptsize Nota em português.};
    \foreach \i in {1,2,3,4,5,6,7,8,9} \filldraw[black] (\i,1) circle (0.025cm);
    \foreach \i in {1,2,3,4,5,6,7,8,9} \node[below] at (\i,1) {\i};
    \foreach \i in {1,3,5,7,9} \filldraw[blue] (\i,1+0.2) circle (0.035cm);
    \draw[->] (-1,2) -- (11,2);
    \node[right] at (11,2) {\scriptsize Nota em ciências naturais.};
    \foreach \i in {1,2,3,4,5,6,7,8,9} \filldraw[black] (\i,2) circle (0.025cm);
    \foreach \i in {1,2,3,4,5,6,7,8,9} \node[below] at (\i,2) {\i};
    \foreach \i in {1,2,3,4,5} \filldraw[blue] (5,2+\i*0.2) circle (0.035cm);
    \draw[->] (-1,4) -- (11,4);
    \node[right] at (11,4) {\scriptsize Nota em ciências humanas.};
    \foreach \i in {1,2,3,4,5,6,7,8,9} \filldraw[black] (\i,4) circle (0.025cm);
    \foreach \i in {1,2,3,4,5,6,7,8,9} \node[below] at (\i,4) {\i};
    \filldraw[blue] (4,4+0.2) circle (0.035cm);
    \filldraw[blue] (6,4+0.2) circle (0.035cm);
    \foreach \i in {1,2,3} \filldraw[blue] (5,4+\i*0.2) circle (0.035cm);
    \draw[red, line width=0.5cm, opacity=0.15] (5,-1) -- (5,5);
    \node[above] at (5,5) {$\underbrace{\mbox{Média, Moda e Mediana}}_{\downarrow}$};
  \end{tikzpicture}
\end{figure}

---

A variáveis _nota em matemática_, _nota em português_, _nota em ciências naturais_, e _nota em ciências humanas_ têm a mesma média, moda e mediana, mas as variáveis não são guais.

Precisamos analisar como os valores são distribuídos.

\regrafina

**Medidas de dispersão**

A ideia é medir a homogeneidade dos valores.

* **Variância: ** $s^2 = \dfrac{(x_1 - \overline{x})^2 + \cdots + (x_n - \overline{x})^2}{n-1}$.
* **Desvio padrão: ** $s = \sqrt{s^2}$ (mesma unidade dos dados).
* **Coeficiente de variação** $cv= \dfrac{s}{\overline{x}} \cdot 100\%$ (adimensional, ou seja, "sem unidade").

\normalsize

## Medidas resumo: exemplo

Podemos usar a função `summarise` do pacote `dplyr` (incluso no pacote `tidyverse`).

```{r}
dados_iris |>
  summarise(
    media = mean(comprimento_sepala),
    mediana = median(comprimento_sepala),
    dp = sd(comprimento_sepala),
    cv = dp / media
  )
```


## Medidas resumo: exemplo

Podemos usar a função  `group_by` para calcular medidas resumo por categorias de uma variável qualitativa.

```{r}
tabela <- dados_iris |>
  group_by(especies) |>
  summarise(
    media = mean(comprimento_sepala),
    mediana = median(comprimento_sepala),
    dp = sd(comprimento_sepala),
    cv = dp / media
  )
tabela
```

## Medidas de resumo\newline Exercício

* Calcule média, mediana, o desvio padrão e coeficiente de variação para a variável `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx` por gênero (`tp_sexo`).
* Calcule média, mediana, o desvio padrão e coeficiente de variação para a variável `nu_nota_cn` do conjunto de dados `amostra_enem_salvador.xlsx` por gênero (`tp_sexo`).
* Calcule média, mediana, o desvio padrão e coeficiente de variação para a variável `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx` por raça (`tp_cor_raca`).
* Calcule média, mediana, o desvio padrão e coeficiente de variação para a variável `nu_nota_cn` do conjunto de dados `amostra_enem_salvador.xlsx` por raça (`tp_cor_raca`).

## Quantis

**Ideia**

$q(p)$ é um valor que satisfaz;

* $100 \cdot p\%$ das observações $x_i$ satisfazem $x_i \leq q(p)$
* $100 \cdot (1-p)\%$ das observações satisfazem $x_i \geq q(1-p)$

\regrafina

**Alguns quantis especiais**

* *Primeiro quartil:* $q_1 = q(0,25)$
* *Primeiro quartil:* $q_2 = q(0,5)$
* *Primeiro quartil:* $q_3 = q(0,75)$

## Quantis

* Existem diversas formas para calcular os quantis.
* Várias formas de calcular os quantis.
* Vamos ver apenas 9 formas neste curso usadas na linguagem `R` e propostas por @hyndman1996sample.

Considere uma amostra $x_1,\dots, x_n$. O $i$-ésimo menor valor da amostra é chamado de estatística de ordem $i$ e é denotado por $x_{(i)}$. Mais precisamente:
$$
\#\{x \in\{1, \dots, n\} \mid x \leq x_{(i)} \}=i.
$$

---

As aproximações dos quantis satisfazem a seguinte equação:
$$
\hat{Q}(p) = (1-\gamma)x_{(j)} + \gamma x_{(j+1)},
$$
onde

* $j=\lfloor p \cdot n +m \rfloor$ onde $m\in \mathbb{R}$;
* $g=p\cdot n + m - j$;
* $0 \leq \gamma \leq 1$ é uma função de $g$ e $j$.

Vamos usar a variável dos dados apresentados na Tabela 2.1 [página 28 de @morettin2017estatistica]:

```{r}
dados_MB <- read_xlsx("dados/brutos/companhia_MB.xlsx")
p <- c(1/8, 1/4, 1/2, 3/4, 7/8)
salario <- dados_MB$salario
```


## Quantis

### Método 1 - `type = 1`

:::{.columns}

:::{.column width="50%"}

* $m=0$;
* $j=\lfloor p\cdot n \rfloor$;

:::

:::{.column width="50%"}

* $g = p\cdot n - \lfloor p\cdot n \rfloor$;
* $\gamma = \begin{cases} 1, & g > 0\\ 0,& g = 0 \end{cases}.$

:::

:::

```{r}
(quantil_tipo_1 <- quantile(salario, probs = p, type = 1))
```

### Método 2 - `type = 2`

:::{.columns}

:::{.column width="50%"}
Método implementado pelo [SAS](https://www.sas.com/pt_br/home.html).

* $m=0$;
* $j=\lfloor p\cdot n \rfloor$;

:::

:::{.column width="50%"}

* $g = p\cdot n - \lfloor p\cdot n \rfloor$.
* $\gamma = \begin{cases} 1,& g> 0\\ \frac{1}{2},& g = 0 \end{cases}.$

:::

:::

```{r}
(quantil_tipo_2 <- quantile(salario, probs = p, type = 2))
```

## Quantis

### Método 3 - `type = 3`

:::{.columns}

:::{.column width="50%"}

* $m=-\frac{1}{2}$;
* $j=\lfloor p\cdot n + m \rfloor$;

:::

:::{.column width="50%"}

* $g = p\cdot n + m- \lfloor p\cdot n+m \rfloor$;
* $\gamma = \begin{cases} 1, & g > 0\\ 0,& g = 0 \text{ e j é par}\\ 1,& g = 0 \text{ e j é ímpar} \end{cases}.$

:::

:::

```{r}
(quantil_tipo_3 <- quantile(salario, probs = p, type = 3))
```

### Método 4 - `type = 4`

:::{.columns}

:::{.column width="30%"}

* $m=0$;
* $j=\lfloor p\cdot n \rfloor$;

:::

:::{.column width="70%"}

* $g = p\cdot n - \lfloor p\cdot n \rfloor$.
* $\gamma = \begin{cases} f_i,& g> 0\\ 0,& g = 0 \end{cases}$, em que $f_i = \frac{p - \frac{i}{n}}{\frac{1}{n}}$.

:::

:::

```{r}
(quantil_tipo_4 <- quantile(salario, probs = p, type = 4))
```

## Quantis

### Método 5 - `type = 5`

Método apresentado por @morettin2017estatistica.

:::{.columns}

:::{.column width="30%"}

* $m=-\frac{1}{2}$;
* $j=\lfloor p\cdot n + m \rfloor$;

:::

:::{.column width="70%"}

* $g = p\cdot n + m- \lfloor p\cdot n+m \rfloor$;
* $\gamma = \frac{p-p_i}{p_{i+1} - p_i}\cdot I_{(p_i, p_{i+1})}$, em que $p_i=\frac{i-0,5}{n}$.

:::

:::

```{r}
(quantil_tipo_5 <- quantile(salario, probs = p, type = 5))
```

### Método 6 - `type = 6`

Método usado por SPSS e Minitab.

:::{.columns}

:::{.column width="50%"}

* $m=p$;
* $j=\lfloor p\cdot n + m \rfloor$;

:::

:::{.column width="50%"}

* $g = p\cdot n +m - \lfloor p\cdot n +m \rfloor$.
* $\gamma = g$.

:::

:::

```{r}
(quantil_tipo_6 <- quantile(salario, probs = p, type = 6))
```

## Quantis

### Método 7 - `type = 7`

Método usado pela linguagem `R` e `S`.

:::{.columns}

:::{.column width="30%"}

* $m=1-p$;
* $j=\lfloor p\cdot n + m \rfloor$;

:::

:::{.column width="70%"}

* $g = p\cdot n + m- \lfloor p\cdot n+m \rfloor$;
* $\gamma = g$.

:::

:::

```{r}
(quantil_tipo_7 <- quantile(salario, probs = p, type = 7))
```

### Método 8 - `type = 8`


:::{.columns}

:::{.column width="50%"}

* $m=\frac{p+1}{3}$;
* $j=\lfloor p\cdot n + m \rfloor$;

:::

:::{.column width="50%"}

* $g = p\cdot n +m - \lfloor p\cdot n +m \rfloor$.
* $\gamma = g$.

:::

:::

```{r}
(quantil_tipo_8 <- quantile(salario, probs = p, type = 8))
```


## Quantis

### Método 9 - `type = 9`

Adequado com normalidade.

:::{.columns}

:::{.column width="30%"}

* $m=frac{p}{4}+\frac{3}{8}$;
* $j=\lfloor p\cdot n + m \rfloor$;

:::

:::{.column width="70%"}

* $g = p\cdot n + m- \lfloor p\cdot n+m \rfloor$;
* $\gamma = g$.

:::

:::

```{r}
(quantil_tipo_9 <- quantile(salario, probs = p, type = 9))
```

---


```{r}
#| echo: false
tipos <- seq_len(9) |> 
  sapply(\(k) quantile(dados_MB$salario, probs = p, type = k)) |>
  t()
colnames(tipos) <- format(p * 100, big.mark = ".", decimal.mark = ",") |> paste("%")
rownames(tipos) <- NULL
df_tipos <- as_tibble(tipos) |> 
  mutate(tipos = paste("tipos", seq_len(9))) |> 
  dplyr::select(tipos, everything())
knitr::kable(df_tipos, format.args = list(decimal.mark = ",", big.mark = "."),
             caption = "Comparação de alguns quantis calculados usando diferentes métodos de aproximação para a variável \\texttt{salario}.")
```

---

Vamos considerar o caso normal para uma amostra de tamanho 1000.

```{r}
set.seed(12345)
amostra <- rnorm(1000, mean = 500, sd = 100)
```


```{r}
#| echo: false

tipos <- seq_len(9) |> 
  sapply(\(k) quantile(amostra, probs = p, type = k)) |> 
  t()
tipos <- rbind(
  qnorm(p, mean = 500, sd = 100),
  tipos
)

colnames(tipos) <- format(p * 100, big.mark = ".", decimal.mark = ",") |> paste("%")
rownames(tipos) <- NULL
df_tipos <- as_tibble(tipos) |> 
  mutate(tipos = c("Quantil populacional", paste("tipos", seq_len(9)))) |> 
  dplyr::select(tipos, everything())
knitr::kable(df_tipos, format.args = list(decimal.mark = ",", big.mark = "."),
             caption = "Comparação de alguns quantis calculados usando diferentes métodos de aproximação para a distribuição normal com média 500 e desvio padrão 100.")
```


## Quantis

```{r}
dados_iris |>
  group_by(especies) |>
  summarise(
    q1 = quantile(comprimento_sepala, 0.25),
    q2 = quantile(comprimento_sepala, 0.5),
    q3 = quantile(comprimento_sepala, 0.75),
    frequencia = n()
  )
```

`n()` calcula a frequência de cada valor de uma variável qualitativa.

## Quantis\newline Exercício

* Calcule o primeiro quartil, segundo quartil e o terceiro quartil para a variável `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx` por gênero (`tp_sexo`). Inclua uma coluna com a frequência da variável `tp_sexo`.
* Calcule o primeiro quartil, segundo quartil e o terceiro quartil para a variável `nu_nota_cn` do conjunto de dados `amostra_enem_salvador.xlsx` por gênero (`tp_sexo`). Inclua uma coluna com a frequência da variável `tp_sexo`.
* Calcule o primeiro quartil, segundo quartil e o terceiro quartil para a variável `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx` por raça (`tp_cor_raca`). Inclua uma coluna com a frequência da variável `tp_cor_raca`.
* Calcule o primeiro quartil, segundo quartil e o terceiro quartil para a variável `nu_nota_cn` do conjunto de dados `amostra_enem_salvador.xlsx` por raça (`tp_cor_raca`). Inclua uma coluna com a frequência da variável `tp_cor_raca`.

## Valor de letra (_letter value_)

* Proposto para ser simples para calcular sumários usando @tukey1977exploratory e @hoaglin1983understanding.
* Medidas de posição e dispersão simples usando apenas estatísticas de ordem.
* Medidas de resumo resistente (alteração em uma pequena parte da amostra tem poucos efeitos nas medidas de resumo).

**Definição**

Lembre que


1. Estatística de ordem $i$ com notação $x_{(i)}$: $i$-ésimo menor valor observado;
1. Posto à esquerda de $x$: $\#\{i \mid x_i \leq x\}$;
1. Posto à direita de $x$: $\#\{i \mid x_i \geq x\}$;
1. Profundidade de $x$: $\min\{\text{Posto à esquerda de }x; \text{Posto à direita de }x\}$;
1. Profundidade de $x_{(j)}$: $\min\{j; n+1-j\}$.

---

* Definimos os valores de letras espeficando a profundadidade.
* Para variáveis quantitativas contínuas, a área a abaixo ou acima (área da cauda) dos valores de letras são aproximadamente potências de $\frac{1}{2}$. 

\tiny

|Estatística|Profundidade|Representação por um letra|Quantidade de valores|área da cauda|
|:----------|:----------:|-------------------------:|--------------------:|------------:|
|Mediana|$\frac{n+1}{2}$|$M$|1|$\frac{1}{2}$|
|Fourths (quartas)|$\frac{\lfloor \text{profundidade da mediana} \rfloor + 1}{2}$|$F$|2|$\frac{1}{4}$|
|Eighths (oitavas)|$\frac{\lfloor \text{profundidade das quartas} \rfloor + 1}{2}$|$E$|2|$\frac{1}{8}$|
|Sixteenths (16 avos)|$\frac{\lfloor \text{profundidade das quartas} \rfloor + 1}{2}$|$D$|2|$\frac{1}{16}$|
|thirty-seconds (32 avos)|$\frac{\lfloor \text{profundidade das 16 avos} \rfloor + 1}{2}$|$D$|2|$\frac{1}{32}$|
|thirty-fourths (64 avos)|$\frac{\lfloor \text{profundidade das 32 avos} \rfloor + 1}{2}$|$C$|2|$\frac{1}{64}$|
|thirty-fourths (128 avos)|$\frac{\lfloor \text{profundidade das 64 avos} \rfloor + 1}{2}$|$B$|2|$\frac{1}{128}$|
|thirty-fourths (256 avos)|$\frac{\lfloor \text{profundidade das 128 avos} \rfloor + 1}{2}$|$B$|2|$\frac{1}{256}$|
|thirty-fourths (512 avos)|$\frac{\lfloor \text{profundidade das 256 avos} \rfloor + 1}{2}$|$B$|2|$\frac{1}{512}$|
|thirty-fourths (1024 avos)|$\frac{\lfloor \text{profundidade das 512 avos} \rfloor + 1}{2}$|$B$|2|$\frac{1}{1024}$|

: Definição de valores de letras.

\normalsize

---

* A profundidade dos extremos (mínimo e máximo) é 1, e usamos o número 1 para representar esses _valores de letras_.
* Com exceção da mediana, toda profundadidade do slide anterior tem dois _valores de letras_: 
    + uma mais perto do mínimo valor observado
    + uma mais perto do máximo valor observado
* Para calcular os _valores de letras_ precisamos que a profundidade seja maior que um.


---

Geralmente, usamos os _valores de letras_ no seguinte diagrama chamada de _diagrama de resumo de cinco números_:

\tikzset{every picture/.style={line width=0.75pt}}      

\begin{figure}
\centering
\caption{Diagrama de resumo de cinco números.}
\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
\draw   (190.79,181.55) -- (189.81,91.05) -- (379.4,89) ;
\draw    (379.4,89) -- (380.38,179.5) ;
\draw (258,94.8) node [anchor=north west][inner sep=0.75pt]   [align=left] {Mediana};
\draw (192,115.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {1 quartil};
\draw (319.6,114) node [anchor=north west][inner sep=0.75pt]   [align=left] {3 quartil};
\draw (193.2,153.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {Mínimo};
\draw (324,151.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {Máximo};
\draw (68.4,35.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {n (tamanho da amostra)};
\draw (64,96) node [anchor=north west][inner sep=0.75pt]   [align=left] {M};
\draw (96,100) node [anchor=north west][inner sep=0.75pt]  [font=\tiny] [align=left] {Profundidade da mediana};
\draw (45.6,67.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {Letra};
\draw (95.2,67.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {Profundidade};
\draw (66,117.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {F};
\draw (96,120) node [anchor=north west][inner sep=0.75pt]  [font=\tiny] [align=left] {Profundidade das quartas};
\draw (67.6,152) node [anchor=north west][inner sep=0.75pt]   [align=left] {1};
\draw (136.8,151.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {1};
\end{tikzpicture}
\end{figure}

---

Podemos adicionar outras letras no diagrama para obter, por exemplo, um diagrama de resumo de nove números:

\begin{figure}
\centering
\caption{Diagrama de resumo de nove números.}
\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300

%Shape: Right Angle [id:dp6451507548785453] 
\draw   (207.85,258.94) -- (208.53,110.2) -- (399.75,111.06) ;
%Straight Lines [id:da6622189196600071] 
\draw    (399.55,110.46) -- (399.15,264.86) ;

% Text Node
\draw (278,114.8) node [anchor=north west][inner sep=0.75pt]   [align=left] {Mediana};
% Text Node
\draw (212.8,143.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {1 quartil};
% Text Node
\draw (340,143.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {3 quartil};
% Text Node
\draw (215.6,228.8) node [anchor=north west][inner sep=0.75pt]   [align=left] {Mínimo};
% Text Node
\draw (338.8,229.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {Máximo};
% Text Node
\draw (88.4,55.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {n (tamanho da amostra)};
% Text Node
\draw (84,116) node [anchor=north west][inner sep=0.75pt]   [align=left] {M};
% Text Node
\draw (116,120) node [anchor=north west][inner sep=0.75pt]  [font=\tiny] [align=left] {Profundidade da mediana};
% Text Node
\draw (65.6,87.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {Letra};
% Text Node
\draw (115.2,87.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {Profundidade};
% Text Node
\draw (86,140.8) node [anchor=north west][inner sep=0.75pt]   [align=left] {F};
% Text Node
\draw (116.4,145.6) node [anchor=north west][inner sep=0.75pt]  [font=\tiny] [align=left] {Profundidade das quartas};
% Text Node
\draw (87,227.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {1};
% Text Node
\draw (159.8,229.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {1};
% Text Node
\draw (86.4,171.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {E};
% Text Node
\draw (114.4,175.6) node [anchor=north west][inner sep=0.75pt]  [font=\tiny] [align=left] {Profundidade das oitavas};
% Text Node
\draw (212.4,172) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {oitava inferior};
% Text Node
\draw (316.8,172.8) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {oitava superior};
% Text Node
\draw (85.6,201.6) node [anchor=north west][inner sep=0.75pt]   [align=left] {D};
% Text Node
\draw (114.4,208) node [anchor=north west][inner sep=0.75pt]  [font=\tiny] [align=left] {Profundidade das 16 avos};
% Text Node
\draw (211.6,204.4) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {16 avo inferior};
% Text Node
\draw (316,205.2) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {16 avo superior};


\end{tikzpicture}

\end{figure}

## Valor de letra (_letter value_)

* Por que usamos a profundidade $\frac{n+1}{2}$ para a mediana em vez de $\frac{n}{2}$?
* Por que usamos a profundidade $\frac{\lfloor \text{profundidade anterior} \rfloor + 1}{2}$ em vez de $\frac{\lfloor \text{profundidade anterior} \rfloor}{2}$ (exceto os extremos)?

\regrafina



* É simples usar $\frac{\lfloor \text{profundidade anterior} \rfloor + 1}{2}$;

Seja $X_i \stackrel{\text{iid}}{\sim} F$ e considere as estatísticas de ordem $X_{(1)}, \dots, X_{(n)}$.

Então $F(X_i) \sim U(0,1)$ , e $U_{(i)}=F(X_{(i)}), i=1,\dots,n$ pois $F$ é não decrescente.

Pode-se provar que:

1. $U_{(i)}$ tem FDA dada por $F_{U_{(i)}}(x) = \sum_{j=i}^{n} \binom{n}{j} x^j(1-x)^{n-j}$;
1. $U_{(i)}$ tem Função Densidade de Probabilidade (FDP) dada por $f_{U_{(i)}}(x) =  \frac{n!}{(i-1)! (n-r)!} x^{i-1}(1-x)^{n-i}$;
1. $\espe[U_{(i)}] = \frac{i}{n+1}$;
1. $\espe[U_{(i)} - U_{(i-1)}] = \frac{1}{n+1}$.

---

Em média, temos que:

\tikzset{every picture/.style={line width=0.75pt}}      

\begin{figure}
\centering

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300

%Straight Lines [id:da9697108800550001] 
\draw    (130.2,109.8) -- (370.2,109.8) ;
%Shape: Circle [id:dp6708000057628175] 
\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (166.4,110.1) .. controls (166.4,108.5) and (167.7,107.2) .. (169.3,107.2) .. controls (170.9,107.2) and (172.2,108.5) .. (172.2,110.1) .. controls (172.2,111.7) and (170.9,113) .. (169.3,113) .. controls (167.7,113) and (166.4,111.7) .. (166.4,110.1) -- cycle ;
%Shape: Circle [id:dp6641192243897238] 
\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (206.8,110.1) .. controls (206.8,108.5) and (208.1,107.2) .. (209.7,107.2) .. controls (211.3,107.2) and (212.6,108.5) .. (212.6,110.1) .. controls (212.6,111.7) and (211.3,113) .. (209.7,113) .. controls (208.1,113) and (206.8,111.7) .. (206.8,110.1) -- cycle ;
%Shape: Circle [id:dp15485081925049138] 
\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (244.8,110.1) .. controls (244.8,108.5) and (246.1,107.2) .. (247.7,107.2) .. controls (249.3,107.2) and (250.6,108.5) .. (250.6,110.1) .. controls (250.6,111.7) and (249.3,113) .. (247.7,113) .. controls (246.1,113) and (244.8,111.7) .. (244.8,110.1) -- cycle ;
%Shape: Circle [id:dp21112009656826347] 
\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (327.8,109.1) .. controls (327.8,107.5) and (329.1,106.2) .. (330.7,106.2) .. controls (332.3,106.2) and (333.6,107.5) .. (333.6,109.1) .. controls (333.6,110.7) and (332.3,112) .. (330.7,112) .. controls (329.1,112) and (327.8,110.7) .. (327.8,109.1) -- cycle ;
%Straight Lines [id:da36807862397370217] 
\draw    (170.4,120.6) -- (208.6,121) ;
\draw [shift={(208.6,121)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
\draw [shift={(170.4,120.6)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
%Straight Lines [id:da9495809539107128] 
\draw    (212.8,121.8) -- (251,122.2) ;
\draw [shift={(251,122.2)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
\draw [shift={(212.8,121.8)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
%Straight Lines [id:da5633477916690803] 
\draw    (331.6,119.4) -- (369.8,119.8) ;
\draw [shift={(369.8,119.8)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
\draw [shift={(331.6,119.4)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
%Straight Lines [id:da9067596530968447] 
\draw    (128.8,120.2) -- (167,120.6) ;
\draw [shift={(167,120.6)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;
\draw [shift={(128.8,120.2)}, rotate = 180.6] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (0,5.59) -- (0,-5.59)   ;

% Text Node
\draw (276.4,92.4) node [anchor=north west][inner sep=0.75pt]   [align=left] {...};
% Text Node
\draw (156.4,87) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize]  {$U_{(}{}_{1}{}_{)}$};
% Text Node
\draw (196,87.8) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize]  {$U_{(}{}_{2}{}_{)}$};
% Text Node
\draw (234.8,87.8) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize]  {$U_{(}{}_{3}{}_{)}$};
% Text Node
\draw (317.2,87.8) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize]  {$U_{(}{}_{n}{}_{)}$};
% Text Node
\draw (124.8,87) node [anchor=north west][inner sep=0.75pt]   [align=left] {0};
% Text Node
\draw (364.8,86.2) node [anchor=north west][inner sep=0.75pt]   [align=left] {1};
% Text Node
\draw (172.4,122) node [anchor=north west][inner sep=0.75pt]  [font=\scriptsize]  {$\frac{1}{n+1}$};
% Text Node
\draw (214.8,123.2) node [anchor=north west][inner sep=0.75pt]  [font=\scriptsize]  {$\frac{1}{n+1}$};
% Text Node
\draw (333.6,120.8) node [anchor=north west][inner sep=0.75pt]  [font=\scriptsize]  {$\frac{1}{n+1}$};
% Text Node
\draw (130.8,121.6) node [anchor=north west][inner sep=0.75pt]  [font=\scriptsize]  {$\frac{1}{n+1}$};


\end{tikzpicture}
\caption{Representação da distância média entre $U_{(i)}$ e $U_{(i-1)}$ para $i=1, \dots, n+1$, onde $U_{(0)}=0$ e $U_{(n+1)}=1$.}
\end{figure}

Para achar a metade dessa reta entre 0 e 1 dividida em $n+1$ intervalos, pegamos o ponto $\frac{n+1}{2}$ deta reta.

Esta é a razão para usarmos $\frac{\lfloor \text{profundidade anterior} \rfloor + 1}{2}$.

## Valor de letra (_letter value_)

* **Pacote:** `lettervalue`
* Parêmetros das funções `letter_value`
  - `x`: vetor numérico.
  - `level`: indicação da profundadidade do diagrama de resumo (valores entre 2 e 9). Valor padrão é 2.
  - `na_rm`: argumento booleano. Por padrão, os valores faltantes são retirados.

```{r}
p_load(lettervalue)
letter_value(dados_iris$comprimento_sepala, level = 3)
```

## Valor de letra (_letter value_)\newline Exercício

Para o conjunto de dados `enem_amostra_salvador.xlsx`, construa:

* o diagrama de resumo com 5 números para a variável `nu_nota_mt`;
* o diagrama de resumo com 7 números para a variável `nu_nota_mt`;
* o diagrama de resumo com 5 números para a variável `nu_nota_lc`;
* o diagrama de resumo com 7 números para a variável `nu_nota_lc`.

## Medidas de resumo usando valores de letra

### Medidas de posição

* Mediana: $$M$$
* Trimédia: $$\frac{\text{primeiro quartil}}{4} + \frac{\text{mediana}}{2} + \frac{\text{terceiro quartil}}{4}$$

### Medidas de dispersão

* F-spread: $d_F = F_U - F_L$, onde $F_U$ é o terceiro quartil e $F_L$ é o primeiro quartil;
* F-pseudo sigma: $\frac{d_F}{1,349}$.

### Pontos exteriores

* Valores da amostra que se destacam;
* Valores muito pequenos ou muito grandes (0,7% da amostra);
* abaixo de $1,5\cdot d_F - F_L$ ou acima de $1,5 \cdot d_F + F_U$.

---

**Motivação para F-spread.**

Considere a distribuição $N(\mu, \sigma^2)$:

* O quantil de ordem 25% é $\mu - 0,6745\cdot \sigma$;
* O quantil de ordem 75% é $\mu + 0,6745\cdot \sigma$;
* $d_F$ é aproximadamente $\mu + 0,6745\cdot \sigma - (\mu - 0,6745\cdot \sigma) = 1,349\cdot \sigma$;
* $\sigma = \frac{d_F}{1,349}$.

## Medidas de resumo usando valores de letra

Para calcular medidas resumo, usamos a função `summary` em um objeto `lv`.

\small

```{r}
valores_letras <- letter_value(rivers)
summary(valores_letras)
```

\normalsize

## Medidas de resumo usando valores de letra\newline Exercício

Para o conjunto de dados `enem_amostra_salvador.xlsx`, calcule:

* medidas de resumo para a variável `nu_nota_mt`;
* medidas de resumo para a variável `nu_nota_lc`;
* medidas de resumo para a variável `nu_nota_cn`;
* medidas de resumo para a variável `nu_nota_ch`.

# Diagrama de caixa\newline\newline\ _boxplot_

## Diagrama de caixa (ou _boxplot_)

* Permite visualizar: centro (mediana); dispersão (intervalo interquartil); assimetria; e ponto exterior.
* Pontos exteriores: valores observados acima de $LS$ ou abaixo de $LI$.
* Pontos exteriores precisam de nossa atenção.
* Como calcular $LS$ e $LI$:
  - $LS = 1,5 \cdot (q_3 - q1) + q_3$;
  - $LS = -1,5 \cdot (q_3 - q1) + q_1$.


```{r}
#| echo: false
#| out.width: 25%
knitr::include_graphics("boxplot.png")
```


## Diagrama de caixa (ou _boxplot_)

**Medida de dispersão:** distância entre $q_3$ e $q_1$

**Diferença de quartis:** $dq = q_3 - q_1$

```{r}
#| out.width: "85%"
#| echo: false
#| fig.align: center
knitr::include_graphics("motivacao_dq.png")
```

## Diagrama de caixa (ou _boxplot_)

**Assimetria à direita ou positiva:**

* frequências diminuem à direita no histograma
* $q_2$ perto $q_1$: $q_2 - q_1 < q_3 - q_2$

\regrafina

**Assimetria à esquerda ou negativa:** frequências diminuem à esquerda no histograma

* frequências diminuem à direita no histograma
* $q_2$ perto $q_3$: $q_2 - q_1 > q_3 - q_2$

## Diagrama de caixa (ou _boxplot_)

**Assimetria**

```{r}
#| echo: false
#| fig.height: 6
#| out.width: "85%"
tam <- 1000
k <- ceiling(1 + log2(tam))
a <- 1
b <- 15
#------------------------------------------------------------------------------
# assimetria positiva
amostra <- rbeta(tam, shape1 = a, shape2 = b)
p1 <- ggplot(tibble(x = amostra)) +
    geom_histogram(aes(x = x, y = after_stat(density)),
                    bins = k, fill = "blue") +
    theme_gdocs() +
    scale_x_continuous(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "X", y = "Densidade de\n frequência",
        title = "Assimetria à direita ou positiva")

p2 <- ggplot(tibble(x = amostra)) +
    geom_boxplot(aes(x = "", y = x), outlier.shape = NA) +
    theme_calc() +
    scale_x_discrete(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", y = "X", title = "Assimetria à direira ou positiva")

#------------------------------------------------------------------------------
# assimetria negativa
amostra <- rbeta(tam, shape1 = b, shape2 = a)
n1 <- ggplot(tibble(x = amostra)) +
    geom_histogram(aes(x = x, y = after_stat(density)),
                    bins = k, fill = "blue") +
    theme_gdocs() +
    scale_x_continuous(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "X", y = "Densidade de\n frequência",
        title = "Assimetria à esquerda ou negativa")

n2 <- ggplot(tibble(x = amostra)) +
    geom_boxplot(aes(x = "", y = x), outlier.shape = NA) +
    theme_calc() +
    scale_x_discrete(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", y = "X",
        title = "Assimetria à esquerda ou negativa")

#------------------------------------------------------------------------------
# simetria
amostra <- rbeta(tam, shape1 = 5, shape2 = 5)
s1 <- ggplot(tibble(x = amostra)) +
    geom_histogram(aes(x = x, y = after_stat(density)),
                    bins = k, fill = "blue") +
    theme_gdocs() +
    scale_x_continuous(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "X", y = "Densidade de\n frequência",
        title = "Simetria")

s2 <- ggplot(tibble(x = amostra)) +
    geom_boxplot(aes(x = "", y = x), outlier.shape = NA) +
    theme_calc() +
    scale_x_discrete(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", y = "X",
        title = "Simetria")

p1 + p2 + n1 + n2 + s1 + s2 + plot_layout(nrow = 3, byrow =  TRUE)
```


## Diagrama de caixa (ou _boxplot_)

```{r}
#| out.width: 85%
ggplot(dados_iris) +
  geom_boxplot(aes(x = "", y = comprimento_sepala)) +
  labs(x = "", y = "Comprimento de Sépala") +
  theme_minimal()
```

## Gráficos lado a lado com `patchwork`

* `patchwork` permite que colocar gráficos lado a lado com
  * `+`: figuras ao lado
  * `\`: figuras embaixo
* Para mais detahes, visite a [documentação do patchwork](https://patchwork.data-imaginist.com/articles/patchwork.html)

```{r}
#| out.width: 85%
#| eval: false
sepala <- ggplot(dados_iris) +
  geom_boxplot(aes(x = "", y = comprimento_sepala)) +
  labs(x = "", y = "Comprimento de Sépala") +
  ylim(c(0, 10)) +
  theme_minimal()
petala <- ggplot(dados_iris) +
  geom_boxplot(aes(x = "", y = comprimento_petala)) +
  labs(x = "", y = "Comprimento de Pétala") +
  ylim(c(0, 10)) +
  theme_minimal()
sepala + petala
```

---

```{r}
#| out.width: 100%
#| echo: false
sepala <- ggplot(dados_iris) +
  geom_boxplot(aes(x = "", y = comprimento_sepala)) +
  labs(x = "", y = "Comprimento de Sépala") +
  ylim(c(0, 10)) +
  theme_minimal()
petala <- ggplot(dados_iris) +
  geom_boxplot(aes(x = "", y = comprimento_petala)) +
  labs(x = "", y = "Comprimento de Pétala") +
  ylim(c(0, 10)) +
  theme_minimal()
sepala + petala
```

## Diagrama de caixa\newline Duas ou mais populações

Se adicionarmos uma variável qualitativa em `aes(x = <variável qualitativa>)`, construimos o diagrama de caixa para cada grupo (ou população) de `<variável qualitativa>`.

\vfill

```{r}
#| eval: false
ggplot(dados_iris) +
  geom_boxplot(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "", y = "Comprimento de Sépala") +
  ylim(c(0, 10)) +
  theme_minimal()
```

---

```{r}
#| echo: false
#| out.width: 100%
ggplot(dados_iris) +
  geom_boxplot(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "", y = "Comprimento de Sépala") +
  ylim(c(0, 10)) +
  theme_minimal()
```


## Diagrama de caixa\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`:

*  construa o diagrama de caixa para as variáveis `nu_nota_mt`, `nu_nota_lc`, `nu_nota_ch` e `nu_nota_cn` e os coloque lado a lado usando o pacote `patchwork`.
*  construa o diagrama de caixa para as variável `nu_nota_mt` cada valor de `tp_cor_raca`.
*  construa o diagrama de caixa para as variável `nu_nota_mt` cada valor de `tp_sexo`.
*  construa o diagrama de caixa para as variável `nu_nota_mt` cada valor de `tp_tipo_escola`.

# Medidas de assimetria 

## Medidas de assimetria\newline usando quantis

Podemos mensurar a assimetria usando os quartis.

Note que: 

1. $q_2 - q_1 < q_3 - q_1$ e $q_3 - q_2 < q_3 - q_1$;
1. Se os dados têm assimetria à esquerda (ou negativa): $q_2 - q_1 > q_3 - q_2$;
1. Se os dados têm assimetria à direita (ou positiva): $q_2 - q_1 < q_3 - q_2$;
1. $-1 \leq \frac{q_3 - q_2 - (q_2 - q_1)}{q_3 - q_1} \leq 1$.

---

$B = \frac{q_3 - q_2 - (q_2 - q_1)}{q_3 - q_1}$ é chamado de coeficiente de Bowley.

1. A variável tem assimetria à esquerda (ou negativa) se, e somente se, $B < 0$;
1. A variável tem assimetria à direita (ou positiva) se, e somente se, $B > 0$;
1. A variável tem simetria se, e somente, se $B \approx 0$.

\regrafina

**Não use o coeficiente de Bowley para amostras menores que 100.**

Podemos usar a seguinte **regra de ouro** como referência:

1. se $-0,25 \leq B \leq 0,25$, temos indícios que a variável tem simetria;
1. se $B < -0,25$, temos indícios que a variável tem assimetria negativa;
1. se $B > 0,25$, temos indícios que a variável tem assimetria positiva.

---

```{r}
#| echo: false
#| cache: true

set.seed(12345)
tamanhos <- c(
  25, 30, 50, 60, 70, 80, 90, 100,
  150, 250, 300, 500, 750, 1000
)

n <- 10000
g <- 0.90
lower <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ BowleySkew(rnorm(tam))) |>
      quantile(probs = (1 - g) / 2)
  })

upper <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ BowleySkew(rnorm(tam))) |>
      quantile(probs = (1 + g) / 2)
  })
df <- tibble(tamanhos, lower, upper)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para o coeficiente de Bowley no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```

---

Podemos usar a função `BowleySkew` do pacote `KbMvtSkew` para calcular o coeficiente de Bowley.

Vamos usar o conjunto de dados `rivers` que tem o comprimento dos 141 maiores rios da América do Norte (EUA, Canadá e México).

```{r}
p_load(KbMvtSkew)
BowleySkew(rivers)
```

## Medidas de assimetria\newline usando momentos

Definimos os momentos amostrais por $m_r = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^r$ para $r \geq 1$.

* $m_2$ é uma aproximação para a variância da população.
* $m_1$ é aproximadamente zero.

Note que:

* existe assimetria à direita ou positiva se, e somente se, $m_3 > 0$.
* existe assimetria à esquerda ou negativa se, e somente se, $m_3 < 0$.
* existe simetria se, e somente se, $m_3 = 0$.

Para criarmos uma medida sem unidade, usamos:
$$
g_1 = \frac{m_3}{m_2^\frac{3}{2}}.
$$

## Medidas de assimetria\newline usando momentos

**Melhorias de $g_1$:**

Medida de assimetria usada po SAS, SPSS e Excel:
$$
G_1 = \frac{\sqrt{n(n-1)}}{n-2} \frac{m_3}{m_2^{\frac{3}{2}}};
$$

Método implementado pelo MINITAB:
$$
b_1 = \left( \frac{n-1}{n} \right)^{\frac{3}{2}} \frac{m_3}{m_2^{\frac{3}{2}}}.
$$

---

* Para amostras grandes, $g_1$, $G_1$ e $b_1$ são próximos.
* $g_1$ é a _pior_ estimativa (maior variabilidade nas estimativas), mas está nos livros introdutórios de estatística pela simplificidade;
* $b_1$ é a _melhor_ estimativa no contexto de normalidade;
* $G_1$ é a _melhor_ estimativa no contexto de ausência de normalidade.

Consulte @joanes1998comparing para mais detalhes.

Segundo @doane2011measuring, podemos usar as 3 tabelas seguintes como referência para $g_1$, $G_1$ e $b_1$.

---

```{r}
#| echo: false
#| cache: true

p_load(e1071)

set.seed(12345)
tamanhos <- c(
  25, 30, 50, 60, 70, 80, 90, 100,
  150, 250, 300, 500, 750, 1000
)

n <- 10000
g <- 0.90
lower <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ skewness(rnorm(tam), type = 1)) |>
      quantile(probs = (1 - g) / 2)
  })

upper <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ skewness(rnorm(tam), type = 1)) |>
      quantile(probs = (1 + g) / 2)
  })
df <- tibble(tamanhos, lower, upper)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para $g_1$ no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```

---

```{r}
#| echo: false
#| cache: true

p_load(e1071)

set.seed(12345)
tamanhos <- c(
  25, 30, 50, 60, 70, 80, 90, 100,
  150, 250, 300, 500, 750, 1000
)

n <- 10000
g <- 0.90
lower <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ skewness(rnorm(tam), type = 2)) |>
      quantile(probs = (1 - g) / 2)
  })

upper <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ skewness(rnorm(tam), type = 2)) |>
      quantile(probs = (1 + g) / 2)
  })
df <- tibble(tamanhos, lower, upper)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para $G_1$ no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```

---

```{r}
#| echo: false
#| cache: true

p_load(e1071)

set.seed(12345)
tamanhos <- c(
  25, 30, 50, 60, 70, 80, 90, 100,
  150, 250, 300, 500, 750, 1000
)

n <- 10000
g <- 0.90
lower <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ skewness(rnorm(tam), type = 3)) |>
      quantile(probs = (1 - g) / 2)
  })

upper <- tamanhos |>
  map_dbl(\(tam) {
    seq_len(n) |>
      map_dbl(~ skewness(rnorm(tam), type = 3)) |>
      quantile(probs = (1 + g) / 2)
  })
df <- tibble(tamanhos, lower, upper)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para $b_1$ no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```

## Medidas de assimetria\newline usando momentos

Podemosa usar a função `skewness` do pacote `e1071` para estimar a assimetria usando momentos. Com o argumento `type`, podemos escolher entre $g_1$, $G_1$ e $b_1$:

a. `type = 1`, `skewness` calcula $g_1$;
a. `type = 2`, `skewness` calcula $G_2$;
a. `type = 3`, `skewness` calcula $b_1$ (valor padrão).

## Medidas de assimetria

```{r}
p_load(e1071)
# coeficiente de Bowley
BowleySkew(rivers)

# g_1
skewness(rivers, type = 1)

# G_1
skewness(rivers, type = 2)

# b_1
skewness(rivers, type = 3)
```

## Medidas de assimetria\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`, cheque a assimetria de `nu_nota_mt`, `nu_nota_lc`, `nu_nota_ch` e `nu_nota_cn` usando:

* diagrama de caixa;
* histograma;
* coeficiente de Bowley;
* $g_1$;
* $G_1$;
* $b_1$.

# Medida de curtose

## Medida de curtose

Idea: mede a chance de aparecer _pontos exteriores_ ao amostrador valores desta variável na população, usando a distribuição normal como padrão.

* uma variável com normalidade tem curtose igual a 0. Dizemos que a variável é mesocúrtica (de mesocurtose);
* se a variável que tem menos chance de aparecer _pontos exteriores_, então a curtose é negativa e dizemos que a variável é lepcúrtica (de leptocurtose);
* se a variável que mais chance de aparecer _pontos exterioes_, então a curtose é positiva e dizemos que a variável é platicúrtica (de platicurtose).

Medimos a curtose usando uma função do quarto momento amostral:
$$
g_2 = \frac{m_4}{m_2^2} - 3.
$$

---

Medida usada por SAS, SPSS e Excel:
$$
G_2 = \frac{n-1}{(n-2)(n-3)}\left[ (n+1) \left(\frac{m_4}{m_2^2}-3\right) +6  \right].
$$

Medida usada por MINITAB:
$$
b_2 = \left( \frac{n-1}{n} \right)^2 \frac{m_4}{m_2^2}-3.
$$

---

* Para amostras grandes, $g_1$, $G_1$ e $b_1$ são próximos.
* $g_1$ é a _pior_ estimativa (maior variabilidade nas estimativas), mas está nos livros introdutórios de estatística pela simplificidade;
* $b_1$ é a _melhor_ estimativa no contexto de normalidade;
* $G_1$ é a _melhor_ estimativa no contexto de ausência de normalidade.

Consulte @joanes1998comparing para mais detalhes.

---

```{r}
#| echo: false

tabela <- function(tamanhos, f, g = 0.90, n = 10000) {

  lower <- tamanhos |>
    map_dbl(\(tam) {
      seq_len(n) |>
        map_dbl(~ {{f}}(rnorm(tam))) |>
        quantile(probs = (1 - g) / 2)
    })
  
  upper <- tamanhos |>
    map_dbl(\(tam) {
      seq_len(n) |>
        map_dbl(~ {{f}}(rnorm(tam))) |>
        quantile(probs = (1 + g) / 2)
    })
  
  df <- tibble(tamanhos, lower, upper)
  df
}

tamanhos <- c(
  25, 30, 50, 60, 70, 80, 90, 100,
  150, 250, 300, 500, 750, 1000
)

k <- \(x) kurtosis(x, type = 1)

df <- tabela(tamanhos, k)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para $g_2$ no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```

---

```{r}
#| echo: false

k <- \(x) kurtosis(x, type = 2)

df <- tabela(tamanhos, k)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para $G_2$ no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```

---

```{r}
#| echo: false

k <- \(x) kurtosis(x, type = 3)

df <- tabela(tamanhos, k)

knitr::kable(
  df,
  digits = 2,
  col.names = c("Tamanhos das amostras", "Limite inferior", "Limite superior"),
  caption = "Limite inferior e superior para $b_2$ no contexto de normalidade pelo tamanho da amostra, usando intervalo de confiança com coeficiente de confiança 90%.",
  align = c("c", "c", "c"),
  format.args = list(decimal.mark = ",", big.mark = ".")
)
```


---

Podemos usar a função `kurtosis` do pacote `e1071` para estimar  a curtose. Com o argumento `type`, podemos escolher entre $g_2$, $G_2$ e $b_2$:

a. `type = 1`, `kurtosis` calcula $g_2$;
a. `type = 2`, `kurtosis` calcula $G_2$;
a. `type = 3`, `kurtosis` calcula $b_2$.

## Medida de curtose

```{r}
p_load(e1071)

# g_2
kurtosis(rivers, type = 1)

# G_2
kurtosis(rivers, type = 2)

# b_2
kurtosis(rivers, type = 3)
```

## Medida de curtose\newline Exercício

Para o conjunto de dados `amostra_enem_salvador.xlsx`, cheque a curtose de `nu_nota_mt`, `nu_nota_lc`, `nu_nota_ch` e `nu_nota_cn`, e classifique cada uma dessas variáveis como mesocúrtica, platicúrtica e leptocúrtica usando:

* histograma;
* $g_2$;
* $G_2$;
* $b_2$.

# Violin plot

## Violin plot

* Adaptação do diagrama de caixa proposta por @hintze1998violin.
* **Ideia:** visualizar o formato do histograma através da curva de densidade.
* Recomanda-se usar para amostras com tamanho de amostra **igual ou maior que 30**.
* **Sugestão:** usar diagrama de caixa (com sumário estatístico) e violin plot.

\regrafina

\scriptsize

**Curva de densidade:**

Considere uma amostra aleatória $x_1\, dots, x_n$ da variável $X$. Então, a curva de densidade é dada por:
$$d(x, h) = \frac{1}{n \cdot h} \sum_{i=1}^{n}\delta_i,$$
onde $\delta_i = \begin{cases} 1, & x-\frac{h}{2} \leq x_i \leq x+\frac{h}{2}\\ 0, & \text{caso contrário} \end{cases}$, $h$ é a largura banda usada para estimar no [estimador _kernel_](https://rdrr.io/r/stats/bandwidth.html), e $n$ é tamanho da amostra.

* $h$ deve garantir entre $\left[x - \frac{h}{2}; x + \frac{h}{2}\right]$ entre 10% e 40% dos valores observados.
* Por padrão, $h$ garante que $\left[x - \frac{h}{2}; x + \frac{h}{2}\right]$ tem 15% dos valores observados.

\normalsize

## Violin plot

**Diagrama de caixa não consegue capturar a forma da distribuição dos valores.**

**Exemplo de @hintze1998violin:**

* Vamos amostrar valores da distribuição com densidade dada por 
$$f(x) = 0,5 \cdot  f_X(20\cdot x - 10) + 0,5 \cdot f_Y(20\cdot x - 10),$$
onde $X\sim Beta(2; 6)$ e $Y\sim Beta(2; 0,8)$. Esta distribuição é bimodal.
* Vamos amostrar valores da distribuição uniforme $X \sim U[-10, 10]$.
* Vamos amostrar valores da distribuição normal $X \sim N(0, 54,95)$.

---

```{r}
alpha <- c(2, 2)
beta <- c(6, 0.8)
amostrador <- function(n) {
  indices <- sample.int(2, n, TRUE, prob = c(0.5, 0.5))
  indices |> map_dbl(\(k) {
    20 * rbeta(1, alpha[k], beta[k]) - 10
  })
}
n <- 1000
dados <- tibble(
  bimodal = amostrador(n),
  uniforme = runif(n, -10, 10),
  normal = rnorm(n, 0, sqrt(54.95))
)
```

---

```{r}
#| eval: false
bimodal <- ggplot(dados, aes(x = "")) +
  geom_boxplot(aes(y = bimodal)) + theme_minimal() +
  ylim(c(-10, 10))
uniforme <- ggplot(dados, aes(x = "")) +
  geom_boxplot(aes(y = uniforme)) + theme_minimal() +
  ylim(c(-10, 10))
normal <- ggplot(dados, aes(x = "")) +
  geom_boxplot(aes(y = normal)) + theme_minimal() +
  ylim(c(-10, 10))
bimodal + uniforme + normal
```

---

* Os três diagramas de caixas são semelhantes.
* O diagrama de caixa não consegue identificar as formas das distribuições.

```{r}
#| echo: false
#| out-width: 75%
bimodal <- ggplot(dados, aes(x = "")) +
  geom_boxplot(aes(y = bimodal)) + theme_minimal() +
  ylim(c(-10, 10))
uniforme <- ggplot(dados, aes(x = "")) +
  geom_boxplot(aes(y = uniforme)) + theme_minimal() +
  ylim(c(-10, 10))
normal <- ggplot(dados, aes(x = "")) +
  geom_boxplot(aes(y = normal)) + theme_minimal() +
  ylim(c(-10, 10))
bimodal + uniforme + normal
```


## Violin plot

**Exemplo**

```{r}
#| eval: false
ggplot(dados_iris, aes(x = especies, y = comprimento_petala)) +
  geom_violin() + 
  geom_boxplot(width = 0.1) +
  theme_minimal() +
  labs(x = "Espécies", y = "Comprimento de pétala")
```

---

```{r}
#| echo: false
#| out.width: 100%
ggplot(dados_iris, aes(x = especies, y = comprimento_petala)) +
  geom_violin() + 
  geom_boxplot(width = 0.1) +
  theme_minimal() +
  labs(x = "Espécies", y = "Comprimento de pétala")
```

## Violin plot

Para o conjunto de dados `amostra_enem_salvador.xlsx`:

* Construa o _Violin plot_ para a variável `nu_nota_mt`.
* Construa o _Violin plot_ para a variável `nu_nota_mt` por `tp_cor_raca`.

# LV plot

## LV plot

* **Ideia:** generalização do diagrama de caixa.
* Podemos usar mais valores de letra além de $M$ (mediana) e $F$ (primeiro e terceiro quartis).
* Podemos observar a forma (distribuição) semelhante ao `geom_violin`.
* Menos valores são marcados com pontos exteriores.

\regrafina

```{r}
#| echo: false
#| fig.cap: "`geom_lv` versus `geom_boxplot`."
df <- tibble(x = rexp(1000))

lv <- ggplot(df) +
  geom_lv(aes(x = "", y = x)) +
  labs(x = "geom_lv", y = "") +
  scale_y_continuous(breaks = NULL) +
  theme_minimal() + 
  theme(axis.title = element_text(size = 20)) +
  coord_flip()
dc <- ggplot(df) +
  geom_boxplot(aes(x = "", y = x)) +
  labs(x = "geom_boxplot", y = "") +
  scale_y_continuous(breaks = NULL) +
  theme_minimal() +
  theme(axis.title = element_text(size = 20)) +
  coord_flip()

lv / dc
```

## LV plot

Precisamos determinar:

a. Quantos valores de letra incluir no `geom_lv`?
a. Qual a largura de cada uma das caixas em `geom_lv`?

\regrafina

\destaque{Quantos valores de letra incluir no \texttt{geom\_lv}?}

**Regra 5-8 -** inclui de 5 a 8 valores como pontos exteriores:
$$k = \lfloor \log_2(n) -2 \rfloor.$$

**Proporção constante -** inclui $p\cdot 100\%$ dos valores da amostra serão marcados como pontos exteriores: 
$$k_p = \lfloor \log_2(n) \rfloor - \lfloor \log_2(n \cdot p) \rfloor.$$

---

**Confiabilidade -** inclui o valor de letra de nível $i$ se os intervalos de confiança com coeficiente de confiança $1-\alpha$ para os valores de letra de níveis $i$ e $i+1$ não tem intersecção (veja @lvplot par maiores detalhes):
$$k_{1-\alpha} = \lfloor \log_2(n) \rfloor - \lfloor \log_2(2\cdot z_{1-\frac{\alpha}{2}}^2) \rfloor.$$
Este é o método usado por padrão pelo pacote `lvplot`.

**Erro máximo -** inclui o valor de letra de nível $i$ se o desvio padrão estiver abaixo de um limite estabelecido. O desvio padrão de nível $i$ é dado por
$$DP(LV_i) \approx s \sqrt{\frac{\frac{1}{2^i}\left(1 - \frac{1}{2^i}\right)}{n}}\phi\left(\Phi^{-1}\left(\frac{1}{2^i}\right)\right),$$
onde $LV_i$ é o valor de letra de nível $i$, $\phi$ é a função densidade de probabilidade da distribuição normal padrão e $\Phi$ é a função de distribuição acumulada da distribuição normal padrão.

----

\destaque{Quantos valores de letra incluir no \texttt{geom\_lv}?}

* **linear -** largura da caixa é inversamente proporcional ao nível do valor de letra (ou seja, as larguras das caixas diminuem sucessivamente de forma linear). Este é o método usado por padrão pelo pacote `lvplot`.
* **área -** a largura da caixa é inversamente proporcional a $2^{i+1}\lvert LV_i - LV_{i+1} \rvert$ (a área da caixa tem aproximadamente a $\frac{1}{2^{i+1}}$).
* **height -** a largura da caixa é aproximadamente $\frac{1}{2^i}$.

## LV plot

Para o conjunto de dados `amostra_enem_salvador.xlsx`:

* Construa o _lv plot_ para a variável `nu_nota_mt`.
* Construa o _lv plot_ para a variável `nu_nota_mt` por `tp_cor_raca`.


# Ramos-e-folhas

## Ramos-e-folhas

* Alternativa para histograma quando $20 \leq \text{tamanho da amostra} \leq 300$.
* Olhar os números não nos apresenta informações.
* Diagrama de ramos-e-folhas é uma forma de escanear rapidamente os dados.
* Simples e rápido de desenhar a mão no papel.
* Facilita na ordenação dos dados para encontrar quantis.
* Não envolve qualquer teoria elaborada ou complexa.
* Valores da amostra são mostrados no diagrama.
* O que podemos achar no diagrama de ramos-e-folhas:
  - simetria
  - dispersão ou distribuição dos valores
  - centralidade (mediana)
  - pontos exteriores (valores isolados do montante)
  - região de concentração dos valores observados
  - regiões sem observações


---

**Desvantagens do histograma:**

* Dados originais não são apresentados.
* Pode ser difícil de desenhar na mão.

\regrafina

\destaque{\large\bf Ideia}

* Cada valor observado é divido em duas partes: _ramo_ e _folha_.
* Criamos uma coluna com os ramos em ordem crescente.
* Para cada ramo, escrevemos as folhas correspondente a cada valor observado.
* **Indesejável:**
    a. Um ramos todos as folhas.
    a. Vários ramos com uma folha.
* Se um ramo tiver muitas folhas, podemos quebrar o ramo em duas linhas:
   a. `*` fica com os dígitos 0, 1, 2, 3, e 4;
   a. `.` ficam com os dígitos 5, 6, 7, 8, e 9.
   
---

* Se os ramos `*` e `.` tiverem muitas folhas, podemos  quebrar o ramos em cinco linhas:
   a. dígitos 0 e 1 ficam na linha `*`;
   a. dígitos 2 e 3 ficam na linha `t` (do inglês _two_ e _three_);
   a. dígitos 4 e 5 ficam na linha `f` (do inglês _four_ e _five_);
   a. dígitos 6 e 7 ficam na linha `s` (do ingles _six_ e _seven_);
   a. dígitos 8 e 9 ficam na linha `.`.
* O ramo com parênteses indica que a mediana está neste ramo.
* Número de linhas no diagrama de ramos-e-folhas:
$$\text{próxima potência de 10 maior que }\frac{R}{L},$$
em que $R=\max\{x_1, \dots, x_n\} - \min\{x_1, \dots, x_n\}$ e $L=\lfloor 10 \cdot \log_{10}(n) \rfloor$, onde $n$ é o tamanho da amostra.
* Não arredonde valores. Trunque os valores em uma casa significativa.

---

* **Posto de $x$** - número de observações menores ou iguais a $x$:
$$\#\{i \in \{1, \dots, n\} \mid x_i \leq x \};$$
* **Profundidade de $x$:**
$$\min\left\{\#\{i \in \{1, \dots, n\} \mid x_i \leq x \}; \#\{i \in \{1, \dots, n\} \mid x_i \geq x \}\right\};$$
* Inclua a esquerda da coluna de ramos uma coluna de profundadidade.
* Se existirem valores isolados, você indicar eles separadamente.

## Ramos-e-folhas

* **Função:** `stem.leaf` do pacote [`aplpack`](https://www.uni-bielefeld.de/fakultaeten/wirtschaftswissenschaften/fakultaet/lehrende-ehemalige/pwolf/wolf_aplpack/index.xml).
* Parâmetros da função `stem`:
  - `x`: vetor numérico
  - `m`: controla a quantidade de ramos. Se `m = 0.5`, `0` e `1` são agrupados no `0`, `2` e `3` são agrupados no `2`, e assim por diantes. Quando aumentamos `m=1`, cria-se o diagrama de ramos-e-folhas padrão. Se `m=2`, cada ramo é quadrado em duas linhas (`*` e `.`). Se `m=3`, cada ramos é quebrado em cinco linhas (`*`, `t`, `f`, `s` e `.`).

\vfill

\regrafina


```{r}
#| eval: false
dados_menstruacao <- read_csv("dados/brutos/menstruacao.csv")
stem.leaf(dados_menstruacao$tamanho_ciclo, m=1)
```

---

```{r}
#| echo: false
dados_menstruacao <- read_csv("dados/brutos/menstruacao.csv")
stem.leaf(dados_menstruacao$tamanho_ciclo, m=1)
```

## Ramos-e-folhas\newline back-to-back

* Comparação de uma mesma variável em duas populações diferentes.
* No lado esquerdo, coloca-se os valores observados para uma população.
* No lado direito, coloca-se os valores observados para a outra população.

\regrafina

\small

```{r}
#| eval: false
df_companhia_MB <- read_xlsx("dados/brutos/companhia_MB.xlsx")
df_solteiro <- filter(df_companhia_MB, estado_civil == "solteiro")
df_casado <- filter(df_companhia_MB, estado_civil == "casado")

stem.leaf.backback(df_solteiro$idade, df_casado$idade, m=2)
```

\normalsize

---

```{r}
#| echo: false
df_companhia_MB <- read_xlsx("dados/brutos/companhia_MB.xlsx")
df_solteiro <- filter(df_companhia_MB, estado_civil == "solteiro")
df_casado <- filter(df_companhia_MB, estado_civil == "casado")

stem.leaf.backback(df_solteiro$idade, df_casado$idade, m=2)
```


## Ramos-e-folhas\newline Exercício

Construa o gráfico de ramos-e-folhas para os seguintes conjunto de dados:

* `rivers` (vetor disponível no `R`).
* variável `erupcoes` do conjunto de dados `velho_fiel` do pacote `dados`.
* variável `comprimento_sepala` do conjunto de dados `iris`.
* compare a variável `comprimento` para os grupos `Vitamina C` e `Suco de laranja` usando ramos-e-folha back-to-back do conjunto de dados `comprimento_dentes`.

# Gráfico quantil-quantil 

## Gráfico quantil-quantil

**Objetivo:** checar se duas variáveis quantitativas tem a mesma distribuição.

\regrafina

* Considere duas variáveis quantitativas $X$ e $Y$ com
  * $X\quad$: $x_1, \dots, x_n$;
  * $Y\quad$: $y_1, \dots, y_m$.
* Considere os quantis de $X$ e $Y$: 
  * $x_{(1)}, \dots, x_{(n)}$;
  * $y_{(1)}, \dots, y_{(m)}$.
* Se $m=n$, cada par $(x_(j), y_{(j)}), \forall j=1, \dots, n$ desenhamos um ponto no plano cartesiano.
* Se $m<n$, cada par $(q_{(\frac{j}{m})}, x_{(m)}), \forall j=1, \dots,m$ desenhamos um ponto no plano cartesiano onde $q_{(\frac{j}{m})}$ é o quantil de ordem $\frac{j}{m}$ na variável $X$.
* Se os pontos estiverem _aproximadamente_ sobre a reta $y=x$, então $X$ e $Y$ tem a mesma distribuição.

## Gráfico quantil-quantil\newline Exemplo

Vamos comparar a altura de 150 crianças de duas escolas privadas de uma região nobre de salvador: escola $A$ e escola $B$.

```{r}
#| eval: false
df_escola_a <- read_xlsx("dados/brutos/escola_a.xlsx")
df_escola_b <- read_xlsx("dados/brutos/escola_b.xlsx")

estat_ordem_a <- sort(df_escola_a$escola_a)
estat_ordem_b <- sort(df_escola_b$escola_b)

tibble(escola_a = estat_ordem_a, escola_b = estat_ordem_b) |> 
  ggplot(aes(escola_a, escola_b)) +
  geom_point(size = 3) +
  geom_abline(intercept = 0, slope = 1, size = 2,
              color = "blue") +
  theme_minimal() +
  labs(x = "Escola A", y = "Escola B")
```

---

```{r}
#| echo: false
#| out-width: 100%
df_escola_a <- read_xlsx("dados/brutos/escola_a.xlsx")
df_escola_b <- read_xlsx("dados/brutos/escola_b.xlsx")

estat_ordem_a <- sort(df_escola_a$escola_a)
estat_ordem_b <- sort(df_escola_b$escola_b)

tibble(escola_a = estat_ordem_a, escola_b = estat_ordem_b) |> 
  ggplot(aes(escola_a, escola_b)) +
  geom_point(size = 3) +
  geom_abline(intercept = 0, slope = 1, size = 2,
              color = "blue") +
  theme_minimal() +
  labs(x = "Escola A", y = "Escola B")
```

## Gráfico quantil-quantil\newline Exemplo

Vamos comparar a altura de 150 crianças de duas escolas:

* escola $A$: escola privada de uma região nobre;
* escola $C$: escola pública de uma região periférica.

```{r}
#| eval: false
df_escola_a <- read_xlsx("dados/brutos/escola_a.xlsx")
df_escola_c <- read_xlsx("dados/brutos/escola_c.xlsx")

estat_ordem_a <- sort(df_escola_a$escola_a)
estat_ordem_c <- sort(df_escola_c$escola_c)

tibble(escola_a = estat_ordem_a, escola_c = estat_ordem_c) |> 
  ggplot(aes(escola_a, escola_c)) +
  geom_point(size = 3) +
  geom_abline(intercept = 0, slope = 1, size = 2,
              color = "blue") +
  theme_minimal() +
  labs(x = "Escola A", y = "Escola C")
```

---

```{r}
#| echo: false
#| out.width: 100%
df_escola_a <- read_xlsx("dados/brutos/escola_a.xlsx")
df_escola_c <- read_xlsx("dados/brutos/escola_c.xlsx")

estat_ordem_a <- sort(df_escola_a$escola_a)
estat_ordem_c <- sort(df_escola_c$escola_c)

tibble(escola_a = estat_ordem_a, escola_c = estat_ordem_c) |> 
  ggplot(aes(escola_a, escola_c)) +
  geom_point(size = 3) +
  geom_abline(intercept = 0, slope = 1, size = 2,
              color = "blue") +
  theme_minimal() +
  labs(x = "Escola A", y = "Escola C")
```


## Gráfico quantil-quantil\newline checando normalidade

* Seja $X$ uma variável quantitativa com amostra $x_1, \dots, x_n$;
* Considere as estatísticas de ordem: $x_{(1)}, \dots, x_{(n)}$;
* Considere os valores padronizados: $z_{(j)} = \frac{x_{(i)} - \bar{x}}{s}, \forall i=1, \dots, n$;
* Considere os quantis da distribuição normal: $q_{(i)} = \Phi^{-1} \left( \frac{i-0.5}{n} \right), \forall i=1, \dots, n$;
* Para cada par $(x_{(i)}, q_{(i)}), \forall i=1, \dots,n$, desenhamos um ponto no plano cartesiano;
* Se os pontos estiverem sobre a reta $y=x$, temos indícios que $X$ tem distribuição normal.

Este gráfico também é chamado \textcolor{titulo}{gráfico de probabilidade normal}.

## Gráfico de probabilidade normal

Vamos checar se a variável `largura_sepala` no conjunto de dados `iris.xlsx` tem distribuição normal.

Vamos usar o pacote [`qqplotr`](https://aloy.github.io/qqplotr/) que é uma extensão do pacote [`ggplot2`](https://ggplot2.tidyverse.org/index.html).

* `stat_qq_point` inclui os pontos no plano cartesiano;
* `stat_qq_line` inclui a reta $y=x$;
* `stat_qq_band(bandType = "ts")` inclui uma faixa ao gráfico. Os pontos precisam estar dentro desta faixa (intervalo de confiança) para indicar a normalidade.

---

```{r}
#| eval: false
p_load(qqplotr)

ggplot(
  dados_iris,
  aes(sample = largura_sepala)
) +
  stat_qq_point(color = "blue") +
  stat_qq_line(size = 1.5, color = "purple") +
  stat_qq_band(bandType = "ts", fill = "red", alpha = 0.25) +
  theme_minimal() +
  labs(
    x = "Quantis teóricos da distribuição normal",
    y = "Quantis amostrais"
  )
```

---

```{r}
#| echo: false
#| out.width: 100%
p_load(qqplotr)

ggplot(
  dados_iris,
  aes(sample = largura_sepala)
) +
  stat_qq_point(color = "blue") +
  stat_qq_line(size = 1.5, color = "purple") +
  stat_qq_band(bandType = "ts", fill = "red", alpha = 0.25) +
  theme_minimal() +
  labs(
    x = "Quantis teóricos da distribuição normal",
    y = "Quantis amostrais"
  )
```

## Gráfico quantil-quantil\newline Exercício

* Verifique se `nu_nota_mt` e `nu_nota_lc` do conjunto de dados `amostra_enem_salvador.xlsx` tem a mesma distribuição usando histograma, _violin plot_, _lv plot_ e gráfico quantil-quantil;
* Verifique se `nu_nota_mt` do conjunto de dados `amostra_enem_salvador.xlsx` tem distribuição normal usando histograma e gráfico quantil-quantil;
* Verifique se `nu_nota_lc` do conjunto de dados `amostra_enem_salvador.xlsx` tem distribuição normal usando histograma e gráfico quantil-quantil.


# Associção entre duas variáveis

## Associação entre duas variáveis quantitativas

**Ideia**: estudar a associação entre duas variáveis quantitativas.

```{r}
#| echo: false
#| out.width: 75%
p_load(patchwork)
p_load(mvtnorm)
tam <- 1000
m_positiva <- rmvnorm(tam, mean = c(0,0), sigma = cbind(c(1, 0.95), c(0.95, 1)))
g1 <- ggplot(tibble(x = m_positiva[, 1], y = m_positiva[, 2])) +
  geom_point(aes(x, y)) +
  theme_calc() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(title = "Associação positiva")

m_negativa <- rmvnorm(tam, mean = c(0,0), sigma = cbind(c(1, -0.95), c(-0.95, 1)))
g2 <- ggplot(tibble(x = m_negativa[, 1], y = m_negativa[, 2])) +
  geom_point(aes(x, y)) +
  theme_calc() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(title = "Associação negativa")

m_nulo <- rmvnorm(tam, mean = c(0,0), sigma = cbind(c(1, 0), c(0, 1)))
g3 <- ggplot(tibble(x = m_nulo[, 1], y = m_nulo[, 2])) +
  geom_point(aes(x, y)) +
  theme_calc() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(title = "Associação nula")

g1 + g2 + g3
```


## Associação entre duas variáveis quantitativas\newline gráfico de dispersão

```{r}
#| eval: false
#| echo: true
ggplot(dados_iris) +
  geom_point(aes(comprimento_petala, comprimento_sepala)) +
  labs(
    x = "Comprimento de pétala",
    y = "Comprimento de sépala"
  ) +
  theme_minimal()
```


---

```{r}
#| out.width: 100%
#| echo: false
ggplot(dados_iris) +
  geom_point(aes(comprimento_petala, comprimento_sepala)) +
  labs(
    x = "Comprimento de pétala",
    y = "Comprimento de sépala"
  ) +
  theme_minimal()
```


## Associação entre duas variáveis quantitativas\newline exercício

* Para o conjunto de dados `amostra_enem_salvador.xlsx`, calcule o coeficiente de correlação linear  entre as variáveis `nu_nota_mt` e `nu_nota_cn`. 
* Para o conjunto de dados `amostra_enem_salvador.xlsx`, calcule o coeficiente de correlação linear  entre as variáveis `nu_nota_mt` e `nu_nota_lc`. 

Inclua o argumento nomeado `alpha = 0.1` na função `geom_point` para incluir opacidade no gráfico de dispersão. Isso ajuda quando temos amostra de tamanho médio e grande.

## Associação entre duas variáveis quantitativas\newline coeficiente de correlação linear de Pearson

Suponha que temos uma amostra duas variáveis quantitativas:

* $X:\quad x_1,\dots, x_n$
* $Y:\quad y_1,\dots, y_n$

Ao padronizarmos os valores de $X$ e $Y$, os seguintes comportamentos vão ocorrer:

* A maioria dos pontos vão estar no primeiro e no terceiro quadrantes do plano cartesiano se, e somente se, $X$ e $Y$ estão positivamente associados.
* A maioria dos pontos vão estar no segundo e no quadrante quadrantes do plano cartesiano se, e somente se, $X$ e $Y$ estão negativamente associados.
* Os pontos vão estar igualmente distribuídos nos quadrantes do plano cartesiano se, e somente se, $X$ e $Y$ não estão associados.

---

```{r}
#| echo: false
#| out.width: 100%
#| fig.cap: Comportamento do gráfico de dispersão para as variáveis quantitativas padronizadas na presença de associação positiva, associção negativa e sem associação.

# tamanho das amostras
tamanho <- 1000
media <- c(0, 0)

rho <- 0.95
amostra <- rmvnorm(tamanho, media, rbind(c(1, rho), c(rho, 1)))
df_positivo <- tibble(
  x = amostra[, 1],
  y = amostra[, 2],
)
positivo <- ggplot(df_positivo, aes(x, y)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  lims(x = c(-5, 5), y = c(-5, 5)) +
  labs(title = "Associação positiva") +
  theme_minimal()

rho <- -0.95
amostra <- rmvnorm(tamanho, media, rbind(c(1, rho), c(rho, 1)))
df_negativo <- tibble(
  x = amostra[, 1],
  y = amostra[, 2],
)
negativo <- ggplot(df_negativo, aes(x, y)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  lims(x = c(-5, 5), y = c(-5, 5)) +
  labs(title = "Associação negativa") +
  theme_minimal()

rho <- 0
amostra <- rmvnorm(tamanho, media, rbind(c(1, rho), c(rho, 1)))
df_nulo <- tibble(
  x = amostra[, 1],
  y = amostra[, 2],
)
nulo <- ggplot(df_nulo, aes(x, y)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  lims(x = c(-5, 5), y = c(-5, 5)) +
  labs(title = "Sem associação") +
  theme_minimal()

positivo + negativo + nulo
```

## Associação entre duas variáveis quantitativas\newline coeficiente de correlação linear de Pearson

Note que:

* $X$ e $Y$ são positivamente associadas:
  a. A maioria dos pontos estão no primeiro e no terceiro quadrantes
  a. A maioria das multiplicações das coordenadas são positivas
* $X$ e $Y$ são positivamente associadas:
  a. A maioria dos pontos estão no segundo e no quadrante quadrantes
  a. A maioria das multiplicações das coordenadas são negativas
* $X$ e $Y$ não são associadas:
  a. Os pontos estão igualmente distribuídos nos quadrantes
  a. As multiplicações das coordenadas estão divididas entre positivas e negativas

\regrafina

**Ideia:** pegar a média das multiplicações das coordenadas:
$$
r = \frac{\left( \frac{x_1 - \bar{x}}{s_x} \right)\cdot \left( \frac{y_1 - \bar{y}}{s_y} \right) + \cdots + \left( \frac{x_n - \bar{x}}{s_x} \right)\cdot \left( \frac{y_n - \bar{y}}{s_y} \right)}{n},
$$
onde $s_x$ é o desvio padrão de $X$ e $s_y$ é o desvio padrão de $Y$.

---

\footnotesize

Para calcular o coeficiente de correção linear de Pearson, usamos as funções `cor` e `cor.test` (não é necessário instalar pacote).

```{r}
dados_iris |> 
  summarise(correlacao = cor(comprimento_petala, comprimento_sepala))
```

\regrafina

```{r}
cor.test(dados_iris$comprimento_sepala, dados_iris$comprimento_petala)
```

\normalsize

## Associação entre duas variáveis quantitativas\newline coeficiente de correlação linear de Pearson\newline Exercício

* Para o conjunto de dados `amostra_enem_salvador.xlsx`, calcule o coeficiente de correlação linear  entre as variáveis `nu_nota_mt` e `nu_nota_cn`. 
* Para o conjunto de dados `amostra_enem_salvador.xlsx`, calcule o coeficiente de correlação linear  entre as variáveis `nu_nota_mt` e `nu_nota_lc`. 


## Associação entre duas variáveis qualitativas

**Ideia**

Sejam $X$ e $Y$ duas variáveis qualitativas com os seguintes valores possíveis:

* $X: A_1, \cdots, A_r$
* $Y: B_1, \cdots, B_s$

Desejamos estudar a associação entre $X$ e $Y$.

\regrafina

**Associação entre $X$ e $Y$**

Suponha que $A_i$ tenha porcentagem $100 \cdot f_i \cdot \%$. Então, $X$ e $Y$ são:

* **não associados:** se ao conhecermos o valor de $Y$ para um elemento da população, **continuamos** com a porcentagem $100 \cdot f_i \%$ deste elemento ter valor de $X$ igual a $A_i$
* **associados:** se ao conhecermos o valor de $Y$ para um elemento da população, **alteramos** a  porcentagem $100 \cdot fi \%$ deste elemento ter valor de $X$ igual a $A_i$

## Associação entre duas variáveis qualitativas\newline Exemplo de associação

Um pesquisador interessado em estudar a associação entre Câncer e o tabagismo coletou uma amostra com 300 indivíduos e obteve a tabela de distribuição de frequência conforme Tabela \ref{tab_associacao}. Você diria que as duas variáveis estão associadas?
\begin{table}[htbp]
	\centering
	\caption{Tabela de contingência entre Câncer e Tabagismo.}
	\label{tab_associacao}
	\begin{tabular}{l|cc|l}
		\toprule[0.05cm]
		& \multicolumn{2}{|c|}{Câncer} & \\ \cmidrule{2-3}
		Tabagismo & Não & Sim & Total\\ \midrule[0.05cm]
		Não-Fumante & 200 & 0 & 200 \\
		Fumante & 0 & 100 & 100\\ \midrule[0.05cm]
		Total & 200 & 100 & 300\\ \bottomrule[0.05cm]
	\end{tabular}
\end{table}

---

Precisamos de uma referência e podemos calcular a frequência relativa ao total das colunas ou total das linhas. Neste exemplo, vamos usar o total das linhas.
\begin{table}[htbp]
	\centering
	\caption{Tabela de contingência com frequência relativa ao total das linhas.}
	\label{tab:associacao_rel}
	\scalebox{0.80}{
	\begin{tabular}{l|ll|l}
		\toprule[0.05cm]
		& \multicolumn{2}{|c|}{Câncer (Y)} & \\ \cmidrule{2-3}
		Tabagismo (X) & Não & Sim & Total\\ \midrule[0.05cm]
		Não-Fumante & $\frac{200}{200}\cdot 100 = 100\%$ & {\color{brown} $\frac{0}{200}\cdot 100 = 0\%$} & $\frac{200}{200}\cdot 100= 100\%$ \\
		Fumante & $\frac{0}{100}\cdot 100 = 0\%$  & {\color{blue} $\frac{100}{100}\cdot 100= 100\%$} &  $\frac{100}{100}\cdot 100=100\%$ \\ \midrule[0.05cm]
		Total & $\frac{200}{300}\cdot 100= 66,67\%$ & {\color{red} $\frac{100}{300}\cdot 100 = 33,33\%$}  & $\frac{300}{300}\cdot 100= 100\%$ \\ \bottomrule[0.05cm]
	\end{tabular}
	}
\end{table} 

Note que a probabilidade de um indivíduo ter câncer é \textcolor{red}{  $33,33\%$}, mas
\begin{itemize}
	\item Se o valor de $Y$ é igual ``Não-Fumante'', então a probabilidade do indivíduo ter câncer é {\color{brown} $0\%$};
	\item Se o valor de $Y$ é igual ``Fumante'', então a probabilidade do indvíduo ter câncer é {\color{blue} $100\%$}.
\end{itemize}

---

```{r}
#| echo: false
#| label: associação de variáveis qualitativas
#| out-width: 100%

df <- tibble(
  tabagismo = c("Não-fumante", "Fumante"),
  sim = c(0, 100),
  nao = c(200, 0)
)
df <- df |>
  pivot_longer(cols = c("sim", "nao"), names_to = "cancer",
               values_to = "frequencia") |>
  mutate(cancer = fct(cancer)) |> 
  mutate(cancer = fct_recode(cancer, "Não" = "nao", "Sim" = "sim"))

g1 <- ggplot(df) +
  geom_bar(aes(x = tabagismo, y = frequencia, fill = cancer), stat = "identity", position = "fill") +
  scale_y_continuous(labels = label_percent()) +
  labs(x = "Tabagismo", y = "Frequência", fill = "Câncer") +
  theme_minimal()

g2 <- ggplot(df) +
  geom_bar(aes(x = tabagismo, y = frequencia, fill = cancer), stat = "identity", position = "dodge") +
  # scale_y_continuous(labels = label_percent()) +
  labs(x = "Tabagismo", y = "Frequência", fill = "Câncer") +
  theme_minimal()

g1 + g2
```

## Associação entre duas variáveis qualitativas\newline Exemplo de ausência de associação

Um pesquisador está interessado em estudar a associação entre Gênero e Tabagismo. Para isso, ele coletou uma amostra de 300 de elementos da população e obteve a tabela contingência na Tabela \ref{tab-nao-associacao}.
\begin{table}[htbp]
	\centering
	\caption{Tabela de contingência entre Gênero e Tabagismo.}
	\label{tab-nao-associacao}
	\begin{tabular}{l|cc|l}
		\toprule[0.05cm]
		& \multicolumn{2}{|c|}{Gênero} & \\ \cmidrule{2-3}
		Tabagismo & Homem & Mulher & Total\\ \midrule[0.05cm]
		Não-Fumante & 80 & 40 & 120\\
		Fumante & 120 & 60 & 180\\ \midrule[0.05cm]
		Total & 200 & 100 & 300\\ \bottomrule[0.05cm]
	\end{tabular}
\end{table}


---

Precisamos de uma referência e podemos calcular a frequência relativa ao total das colunas ou total das linhas. Neste exemplo, vamos usar o total das colunas.
\begin{table}[htbp]
	\centering
	\caption{Tabela de distribuição de frequência relativa ao total das colunas.}
	\label{tab:nao-associacao_rel}
	\scalebox{0.80}{
	\begin{tabular}{l|ll|l}
		\toprule[0.05cm]
		& \multicolumn{2}{|c|}{Gênero (Y)} & \\ \cmidrule{2-3}
		Tabagismo (X) & Homem & Mulher & Total\\ \midrule[0.05cm]
		Não-Fumante & {\color{brown} $\frac{80}{200}\cdot 100 = 40\%$} &  {\color{blue}$\frac{40}{100}\cdot 100 = 40\%$} & {\color{red}$\frac{120}{300}\cdot 100= 40\%$} \\
		Fumante & $\frac{120}{200}\cdot 100 = 60\%$  &  $\frac{60}{100}\cdot 100= 60\%$ &  $\frac{180}{300}\cdot 100=60\%$ \\ \midrule[0.05cm]
		Total & $\frac{200}{200}\cdot 100= 100\%$ &  $\frac{100}{100}\cdot 100 = 100\%$  & $\frac{300}{300}\cdot 100= 100\%$ \\ \bottomrule[0.05cm]
	\end{tabular}
	}
\end{table} 

Note que a probabilidade de um indivíduo ser Fumante é \textcolor{red}{$40\%$}, mas
\begin{itemize}
	\item Se o valor de $Y$ é igual Homem, então a probabilidade do indvíduo ser Fumante é {\color{brown} $40\%$};
	\item Se o valor de $Y$ é igual Mulher, então a probabilidade do indvíduo ser Fumante é {\color{blue} $40\%$}.
\end{itemize}

---

```{r}
#| echo: false
#| label: sem associação 
#| out.width: 100%

df <- tibble(
  tabagismo = c("Não-fumante", "Fumante"),
  homem = c(80, 120),
  mulher = c(40, 60)
)
df <- df |>
  pivot_longer(cols = c("homem", "mulher"), names_to = "Gênero",
               values_to = "frequencia") |> 
  mutate(`Gênero` = fct(`Gênero`) |> 
           fct_recode("Homem" = "homem", "Mulher" = "mulher"))

g1 <- ggplot(df) +
  geom_bar(aes(x = tabagismo, y = frequencia, fill = `Gênero`), stat = "identity", position = "fill") +
  scale_y_continuous(labels = label_percent()) +
  labs(x = "Tabagismo", y = "Frequência", fill = "Gênero") +
  theme_minimal()

g2 <- ggplot(df) +
  geom_bar(aes(x = tabagismo, y = frequencia, fill = `Gênero`), stat = "identity", position = "dodge") +
  labs(x = "Tabagismo", y = "Frequência", fill = "Gênero") +
  theme_minimal()

g1 + g2
```

## Associação entre duas variáveis qualitativas\newline Exemplo

Vamos checar a associação entre `fundacao_tipo` e `geral_condicao`.

\vspace{0.5cm}

\small

```{r}
#| warning: false
#| eval: false
dados_casas <- read_xlsx("dados/brutos/casas.xlsx")
ggplot(dados_casas) +
  geom_bar(aes(x = fundacao_tipo, fill = geral_condicao),
          position = "fill") +
  labs(x = "Tipo de fundação da casa", y = "Porcentagem",
      fill = "Condição geral") +
  scale_y_continuous(labels = scales::label_percent()) +
  theme_minimal()
```

\normalsize

---

```{r}
#| warning: false
#| echo: false
#| out.width: 100%
dados_casas <- read_xlsx("dados/brutos/casas.xlsx")
ggplot(dados_casas) +
  geom_bar(aes(x = fundacao_tipo, fill = geral_condicao), position = "fill") +
  labs(x = "Tipo de fundação da casa", y = "Porcentagem", fill = "Condição geral") +
  scale_y_continuous(labels = scales::label_percent()) +
  theme_minimal()
```

## Associação entre duas variáveis qualitativas\newline Gráfico de barras

Podemos agrupar as barras por grupos para analisar a  associação entre duas variáveis qualitativas.

\vspace{0.5cm}

\small

```{r}
#| warning: false
#| eval: false
dados_casas <- read_xlsx("dados/brutos/casas.xlsx")
ggplot(dados_casas) +
  geom_bar(aes(x = fundacao_tipo, fill = geral_condicao),
          position = "dodge") +
  labs(x = "Tipo de fundação da casa", y = "Frequência",
      fill = "Condição geral") +
  theme_minimal()
```

\normalsize

---

```{r}
#| warning: false
#| echo: false
#| out.width: 100%
dados_casas <- read_xlsx("dados/brutos/casas.xlsx")
ggplot(dados_casas) +
  geom_bar(aes(x = fundacao_tipo, fill = geral_condicao), position = "dodge") +
  labs(x = "Tipo de fundação da casa", y = "Frequência", fill = "Condição geral") +
  theme_minimal()
```

## Associação entre duas variáveis qualitativas\newline Gráfico de barras\newline Exercício

* Verifique se existe associação entre as variáveis `q006` e `tp_cor_raca` do conjunto de dados `amostra_enem_salvador.xlsx` usando gráfico de gráficos usando o `position=fill`.
* Verifique se existe associação entre as variáveis `q006` e `tp_sexo` do conjunto de dados `amostra_enem_salvador.xlsx` usando gráfico de gráficos usando o `position=dodge`.

## Associação entre duas variáveis qualitativas\newline Medidas de associação

**Propriedade quando duas variáveis qualitativas não estão associadas.**

\begin{table}[htbp]
	\centering
	\begin{minipage}{0.45\linewidth}
		\centering
		\caption{Tabela de contingência:  frequência observada.}
		\scalebox{0.65}{
		\begin{tabular}{l|cc|l}
			\toprule[0.05cm]
			& \multicolumn{2}{|c|}{Gênero} & \\ \cmidrule{2-3}
			Tabagismo & Homem & Mulher & Total\\ \midrule[0.05cm]
			Não-Fumante & 80 & 40 & 120\\
			Fumante & 120 & 60 & 180\\ \midrule[0.05cm]
			Total & 200 & 100 & 300\\ \bottomrule[0.05cm]
		\end{tabular}
		}
	\end{minipage}  
	\begin{minipage}{0.45\linewidth}
		\centering
		\caption{Tabela de contingência: frequência esperada.}
		\scalebox{0.65}{
		\begin{tabular}{l|cc|l}
			\toprule[0.05cm]
			& \multicolumn{2}{|c|}{Gênero} & \\ \cmidrule{2-3}
			Tabagismo & Homem & Mulher & Total\\ \midrule[0.05cm]
			Não-Fumante & $\frac{{\color{blue}200}\cdot {\color{brown} 120}}{{\color{red} 300}}= 80$ & $\frac{{\color{blue} 100} \cdot {\color{brown} 120}}{{\color{red} 300}}= 40$ & {\color{brown} 120}\\
			Fumante & $\frac{{\color{blue} 200} \cdot {\color{brown} 180}}{{\color{red} 300}}= 120$ & $\frac{{\color{blue} 100} \cdot {\color{brown} 180}}{{\color{red} 300}} =60$ & {\color{brown} 180}\\ \midrule[0.05cm]
			Total & {\color{blue} 200} & {\color{blue} 100} & {\color{red} 300}\\ \bottomrule[0.05cm]
		\end{tabular}
		}
	\end{minipage}
\end{table}


\textcolor{red}{\textbf{Propriedade importante:}} \textcolor{red}{No contexto de não associação, as tabelas de distribuição de frequência observada e a tabela de distribuição de frequência esperada são iguais.}

## Associação entre duas variáveis qualitativas\newline Medidas de associação

\scriptsize

Considere duas variáveis qualitativas $X$ e $Y$ com valores possíveis:
\begin{itemize}
	\item $X: A_1, A_2, \cdots, A_r$;
	\item $Y: B_1, B_2, \cdots, B_s$;
\end{itemize}
com tabela de contingência conforme tabela abaixo
\begin{table}[htbp]
	\centering
	\begin{tabular}{c|cccc|c}
		\toprule[0.05cm]
		& \multicolumn{4}{|c|}{$Y$} & \\ \cmidrule[0.05cm]{2-5}
		$X$ & $B_1$ & $B_2$ & $\cdots$ & $B_s$ & Total\\ \midrule[0.05cm]
		$A_1$ & $n_{11}$ & $n_{12}$ & $\cdots$ & $n_{1s}$ & $n_{1.}$\\
		$A_2$ & $n_{21}$ & $n_{22}$ & $\cdots$ & $n_{2s}$ & $n_{2.}$\\
		$\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$\\
		$A_r$ & $n_{r1}$ & $n_{r2}$ & $\cdots$ & $n_{rs}$ & $n_{r.} $\\ \midrule[0.05cm]
		Total & $n_{.1}$ & $n_{.2}$ & $\cdots$ & $n_{.s}$ & $n_{..}$\\
		\bottomrule[0.05cm]
	\end{tabular}
\end{table}
em que 
\begin{itemize}
	\item $n_{i.} = n_{i1}+n_{i2}+\cdots+n_{is}, \quad i =1,2, \cdots, r$;
	\item $n_{.j} = n_{1j}+n_{2j}+\cdots+n_{rj}, \quad j =1,2, \cdots, s$;
	\item $n_{..}$ é o tamanho da amostra.
\end{itemize}

\normalsize

---

Se $X$ e $Y$ não estão associadas, temos que $n^\star_{ij}=n_{ij}, \quad i=1,\dots, r,j=1,\dots, s$. Note que se,
\begin{itemize}
	\item Se as distâncias $\dfrac{(n_{ij}-n^\star_{ij})^2}{n^\star{ij}}$ forem pequenas, então as duas variáveis \textbf{não} estão associadas;
	\item Se as distâncias $\dfrac{(n_{ij}-n^\star_{ij})^2}{n^\star{ij}}$ forem grandes, então as duas variáveis estão associadas;
\end{itemize}
então calculamos uma medida chamada qui-quadrado 
\begin{align*}
\chi^2 &= \dfrac{(n_{11} - n^\star_{11})^2}{n^\star_{11}} + \dfrac{(n_{12} - n^\star_{12})^2}{n^\star_{12}} + \cdots + \dfrac{(n_{1s} - n^\star_{1s})^2}{n^\star_{1s}} + \\
&+ \dfrac{(n_{21} - n^\star_{21})^2}{n^\star_{21}} + \dfrac{(n_{22} - n^\star_{22})^2}{n^\star_{22}} + \cdots + \dfrac{(n_{2s} - n^\star_{2s})^2}{n^\star_{2s}} + \\
&\vdots\\
&+\dfrac{(n_{r1} - n^\star_{r1})^2}{n^\star_{r1}} + \dfrac{(n_{r2} - n^\star_{r2})^2}{n^\star_{r2}} + \cdots + \dfrac{(n_{rs} - n^\star_{rs})^2}{n^\star_{rs}},
\end{align*}

---

$\chi^2$ é medida não-negativa, por isso usamos uma padronização entre 0 e 1.

Seja $k=\min\{\text{número de linhas}, \text{número de colunas}\}$ (de tabelas de contingência), e $n$ é o tamanho da amostra.

* **Coeficiente de contingência modificada:** $C=\sqrt{\frac{k \cdot \chi^2}{(k-1)\cdot (n + \chi^2)}}$.
* **Coeficiente V de Cramer:** $C=\sqrt{\frac{\chi^2}{k\cdot \chi^2}}$.

\regrafina

Usamos o pacote [`DescTools`](http://andrisignorell.github.io/DescTools/) para calcular essas medidas.

1. Para calcular o Coeficiente de Contingência Modificada: `ContCoef(x, y)`.
1. Para calcular o Coeficiente V de Cramer: `CramerV(x, y)`.

## Associação entre duas variáveis qualitativas\newline Medidas de associação\newline Exemplo

```{r}
dados_casas <- read_xlsx("dados/brutos/casas.xlsx")

dados_casas |> 
  summarise(
    cont_coef = ContCoef(fundacao_tipo, geral_condicao),
    cramer_v = CramerV(fundacao_tipo, geral_condicao),
  )

```

## Associação entre duas variáveis qualitativas\newline Medidas de associação\newline Exercício

* Verifique se existe associação entre as variáveis `q006` e `tp_cor_raca` do conjunto de dados `amostra_enem_salvador.xlsx` calculando _Coeficiente de Contingência Modificada_.
* Verifique se existe associação entre as variáveis `q006` e `tp_sexo` do conjunto de dados `amostra_enem_salvador.xlsx` calculando _Coeficiente V de Cramer_.

## Associação entre variáveis qualitativas ordinais

Sejam $X$ e $Y$ duas variáveis qualitativas ordinais valores possíveis:

* valores possíveis de $X$: $A_1, \dots, A_n$ com $A_1 < A_2 < \cdots < A_n$;
* valores possíveis de $Y$: $B_1, \dots, B_n$ com $B_1 < B_2 < \cdots < B_n$.

\regrafina

Associação entre $X$ e $Y$:

* $X$ e $Y$ estão **positivamente associadas**, se o nível de $Y$ _aumenta_ quando o nível de $X$ _aumenta_ e vice-versa;
* $X$ e $Y$ estão **negativamente associadas**, se o nível de $Y$ _diminui_ quando o nível de $X$ _aumenta_ e vice-versa.

## Associação entre variáveis qualitativas ordinais\newline Medida de associação

Suponha que temos duas variáveis qualitativas ordinais:

* `escolaridade`: `ensino fundamental`, `ensino médio` e `ensino superior` com `ensino fundamental` < `ensino médio` < `ensino superior`;
* `classe_social`: `A`, `B`, `C` e `D` com `D` < `C` < `B` < `A`.

\regrafina

Dizemos

* que duas observações são concordantes se elas se posicionam em posições concordantes nas duas variáveis. 
  + Exemplo: considere duas observações (João e Joaquim)
    - João: `escola = ensino fundamental` e `classe_social = D`
    - Joaquim: `escola = ensino médio` e `classe_social = C`
* que duas observações são concordantes se elas se posicionam em posições discordantes nas duas variáveis.
  + Exemplo: considere duas observações (João e Josué)
    - João: `escola = ensino fundamental` e `classe_social = C`
    - Josué: `escola = ensino médio` e `classe_social = D`

## Associação entre variáveis qualitativas ordinais\newline Medida de associação

* Se a maioria dos pares de observações são concordantes, então $X$ e $Y$ são positivamente associadas.
* Se a maioria dos pares de observações são discordantes, então $X$ e $Y$ são negativamente associadas.
* Se temos mesmo a quantidade de pares concordantes e discordantes, então $X$ e $Y$ então não estão associadas.

\regrafina

Sejam:

* $n_c$ - número de pares de observações concordantes;
* $n_d$ - número de pares de observações disconcordantes.

Então:

$$
\gamma = \frac{n_c - n_d}{n_c + n_d}.
$$
$\gamma$ é chamado de _Coeficiente Gama de Goodman-Kruskal_.

## Associação entre variáveis qualitativas ordinais\newline Medida de associação

* $\gamma >0$ se, e somente se, $X$ e $Y$ estão positivamente associadas;
* $\gamma <0$ se, e somente se, $X$ e $Y$ estão negativamente associadas;
* $\gamma \approx 0$ se, e somente se, $X$ e $Y$ não estão associadas.

## Associação entre variáveis qualitativas ordinais\newline Medida de associação

Como calcular $\gamma$ usando a tabela de contingência? Suponha que temos duas variáveis qualitativas ordinais:

* $X$: $A_1$, $A_2$, $A_3$, $A_4$ e $A_5$ com $A_1 < A_2 < A_3 < A_4 <A_5$;
* $Y$: $B_1$, $B_2$, $B_3$, $B_4$ e $B_5$ com $B_1 < B_2 < B_3 < B_4 <B_5$.

\regrafina

Número de pares de observações concordantes com observações com $X=A_2$ e $Y=B_3$: $n_{23}\cdot (n_{34} + n_{35} + n_{44} + n_{45} + n_{54} + n_{55})$.


\begin{table}
\begin{tabular}{c|ccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{$X$}} & \multicolumn{5}{c}{$Y$}  \\ \cmidrule{2-6}
\multicolumn{1}{c}{}                   & $B_1$ & $B_2$ & $B_3$ & $B_4$ & $B_5$ \\ \midrule
$A_1$                                     & $n_{11}$   &  $n_{12}$  & $n_{13}$   &  $n_{14}$  & $n_{15}$   \\
$A_2$                                     & $n_{21}$   &  $n_{22}$  & \cellcolor{gray} $n_{23}$   &  $n_{24}$  & $n_{25}$   \\
$A_3$                                     & $n_{31}$   &  $n_{32}$  & $n_{33}$   & \cellcolor{LimeGreen}  $n_{34}$  & \cellcolor{LimeGreen} $n_{35}$   \\
$A_4$                                     & $n_{41}$   &  $n_{42}$  & $n_{43}$   & \cellcolor{LimeGreen}  $n_{44}$  & \cellcolor{LimeGreen} $n_{45}$   \\
$A_5$                                     & $n_{51}$   &  $n_{52}$  & $n_{53}$   & \cellcolor{LimeGreen}  $n_{54}$  & \cellcolor{LimeGreen} $n_{55}$   \\
\bottomrule
\end{tabular}
\end{table}

---

Número de pares de observações disconcordantes com observações com $X=A_2$ e $Y=B_3$: $n_{23}\cdot (n_{31} + n_{32} + n_{41} + n_{42} + n_{51} + n_{52})$.


\begin{table}
\begin{tabular}{c|ccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{$X$}} & \multicolumn{5}{c}{$Y$}  \\ \cmidrule{2-6}
\multicolumn{1}{c}{}                   & $B_1$ & $B_2$ & $B_3$ & $B_4$ & $B_5$ \\ \midrule
$A_1$                                     & $n_{11}$   &  $n_{12}$  & $n_{13}$   &  $n_{14}$  & $n_{15}$   \\
$A_2$                                     & $n_{21}$   &  $n_{22}$  & \cellcolor{gray} $n_{23}$   &  $n_{24}$  & $n_{25}$   \\
$A_3$                                     & \cellcolor{WildStrawberry} $n_{31}$   & \cellcolor{WildStrawberry}  $n_{32}$  & $n_{33}$   &  $n_{34}$  & $n_{35}$   \\
$A_4$                                     & \cellcolor{WildStrawberry} $n_{41}$   &  \cellcolor{WildStrawberry} $n_{42}$  & $n_{43}$   &  $n_{44}$  & $n_{45}$   \\
$A_5$                                     & \cellcolor{WildStrawberry} $n_{51}$   & \cellcolor{WildStrawberry}  $n_{52}$  & $n_{53}$   &  $n_{54}$  & $n_{55}$   \\
\bottomrule
\end{tabular}
\end{table}

Fazemos essas contagens em todas as células para obter $n_c$ e $n_d$.

## Associação entre variáveis qualitativas ordinais\newline Medida de associação

Usamos o pacote `DescTools`:

* A função  `GoodmanKruskalGamma(x, y)` calcula o Coeficiente de Goodman-Kruskal entre `x` e `y`.

**`x` e `y` precisam ser fatores (para indicar a ordem das variáveis qualitativas ordinais).**

Use a função `fct` do pacote `forcats` para criar transformar um vetor de caracteres em um fator.

## Associação entre variáveis qualitativas ordinais\newline Medida de associação\newline Exemplo

Vamos usar um conjunto de dados de respostas ao Questionário de dezesseis fatores de personalidade (16PF), e checar as variáveis qualitativas ordinais $A1$ e $A2$ estão associadas.

As perguntas deste questionário podem se consultadas em: `dicionario_psicologia.html`.

---

```{r}
df_16f <- read_csv2("dados/brutos/psicologia.csv")

# A1 e A2 precisam ser fatores
df_16f <- df_16f |> 
  mutate(
    A1 = fct(as.character(A1), levels = paste(0:5)),
    A2 = fct(as.character(A2), levels = paste(0:5))
  )

df_16f |>
  summarise(gk = GoodmanKruskalGamma(A1, A2))

GoodmanKruskalGamma(df_16f$A1, df_16f$A2, conf.level = 0.95)
```

## Associação entre variáveis qualitativas ordinais\newline Medida de associação\newline Exercício

* Verifique se existe associação entre as variáveis `q006` e `q001` do conjunto de dados `amostra_enem_salvador.xlsx` calculando _Coeficiente Gama de Goodman-Kruskal_.
* Verifique se existe associação entre as variáveis `q006` e `q002` do conjunto de dados `amostra_enem_salvador.xlsx` calculando _Coeficiente Gama de Goodman-Kruskal_.

## Associação entre uma variável qualitativa e uma variável quantitativa

```{r}
#| eval: false
boxplot <- ggplot(dados_iris) +
  geom_boxplot(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "Espécies", y = "Comprimento de Sépala", title = "Diagrama de caixa") +
  theme_minimal()
violino <- ggplot(dados_iris) +
  geom_violin(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "Espécies", y = "Comprimento de Sépala", title = "Violino") +
  theme_minimal()
lv <- ggplot(dados_iris) +
  geom_lv(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "Espécies", y = "Comprimento de Sépala", title = "Valores de letra") +
  theme_minimal()
boxplot + violino + lv
```

---

```{r}
#| echo: false
#| out.width: 100%
dados_iris <- read_xlsx("dados/brutos/iris.xlsx")
boxplot <- ggplot(dados_iris) +
  geom_boxplot(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "Espécies", y = "Comprimento de Sépala", title = "Diagrama de caixa") +
  theme_minimal()
violino <- ggplot(dados_iris) +
  geom_violin(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "Espécies", y = "Comprimento de Sépala", title = "Violino") +
  theme_minimal()
lv <- ggplot(dados_iris) +
  geom_lv(aes(x = especies, y = comprimento_sepala)) +
  labs(x = "Espécies", y = "Comprimento de Sépala", title = "Valores de letra") +
  theme_minimal()
boxplot + violino + lv
```

## Associação entre uma variável qualitativa e uma variável quantitativa\newline Exercício

* Para o conjunto de dados `amostra_enem_salvador.xlsx`, compare a variável `nu_nota_mt` por raça (`tp_cor_raca`).
* Para o conjunto de dados `amostra_enem_salvador.xlsx`, compare a variável `nu_nota_cn` por raça (`tp_cor_raca`).
* Coloque os dois gráficos acima lado a lado usando o pacote `patchwork`.

# Números índices

# Customizando tabelas\newline\ usando o pacote `gt`

## Salvando tabelas com o pacote `gt`

Vamos usar o pacote `gt` para customizar a apresentação de uma tabela.

A ideia do pacote `gt` é melhorar apresentação por camadas.

```{r}
#| echo: false
#| out.width: 75%

knitr::include_graphics("gt-table.jpeg")
```

Para mais detalhes, visite [documentação do pacote `gt`](https://gt.rstudio.com/)

## Salvando tabelas com o pacote `gt`

Vamos usar um exemplo para ensinar como usar o pacote `gt`.

\small

```{r}
#| eval: false
tab <- dados_iris |>
  group_by(especies) |>
  summarise(
    m_petala = mean(comprimento_petala),
    dp_petala = sd(comprimento_petala),
    q1_petala = quantile(comprimento_petala, probs = 0.25),
    q2_petala = quantile(comprimento_petala, probs = 0.5),
    q3_petala = quantile(comprimento_petala, probs = 0.75),
    cv_petala = dp_petala / m_petala
  )
tab
```

---

\scriptsize

```{r}
#| echo: false
tab <- dados_iris |>
  group_by(especies) |>
  summarise(
    m_petala = mean(comprimento_petala),
    dp_petala = sd(comprimento_petala),
    q1_petala = quantile(comprimento_petala, probs = 0.25),
    q2_petala = quantile(comprimento_petala, probs = 0.5),
    q3_petala = quantile(comprimento_petala, probs = 0.75),
    cv_petala = dp_petala * 100 / m_petala
  )
tab
```

\normalsize

## Salvando tabelas com o pacote `gt`

**Cabeçalho da tabela:** legenda e sub-legenda da tabela.

* `tab_header`: permite incluir legenda (`title`) e sub-legenda na tabela (`subtitle`)
* `gtsave`: permite salvar objeto `gt`nos formatos `.html`, `.tex` e `.docx`.
* `md`: permite formatação usando a sintaxe `markdown`.
  * Para mais detalhes sobre markdown, consulte [_cheatsheet_ do markdown](https://www.markdownguide.org/cheat-sheet)


```{r}
gt_tab <- gt(tab) |>
  tab_header(
    title = md("**Comprimento de pétala**"),
    subtitle = md("_Algumas estatísticas descritivas_")
  )
gtsave(gt_tab, "output/tabela.html")
gtsave(gt_tab, "output/tabela.tex")
gtsave(gt_tab, "output/tabela.docx")
```

## Salvando tabelas com o pacote `gt`\newline Exercício

1. Calcule a média, o desvio padrão, o primeiro quartil, o segundo quartil e o terceiro quartil para a variável `nu_nota_mt` por raça (`tp_cor_raca`) do conjunto de dados `amostra_enem_salvador.xlsx`e salve o resultado em objeto `tab`.
1. Crie um objeto `gt` com nome `gt_tab` a partir da tabela em `tab`.
1. Inclua uma legenda com o texto "Nota em matemática por raça" e sublegenda "Edição 2021" com a função `tab_header`. 

## Salvando tabelas com o pacote `gt`

* `tab_source`: inclusão de _fonte de dados_dentes


```{r}
#| eval: false
gt_tab <- gt_tab |>
  tab_source_note(
    source_note = md("**Fonte:** Elboração própria.")
  )
gt_tab
```

---

\scriptsize

```{r}
#| echo: false
gt_tab <- gt_tab |>
  tab_source_note(
    source_note = md("**Fonte:** Elboração própria.")
  )
gt_tab
```

\normalsize

## Salvando tabelas com o pacote `gt`\newline Exercício

Inclua _fonte de dados_ usando a função `tab_source_note` como texto "Fonte: elaboração própria." no objeto `gt_tab`.

## Rótulo (legenda) para grupo de linhas

`tab_row_group`: permite colocar um _rótulo_ para um grupo de linhas.


```{r}
#| eval: false
gt_tab <- gt_tab |>
  tab_row_group(
    rows = c(1, 3),
    label = md("_Espécies principais_")
  )
gt_tab
```

---

\footnotesize

```{r}
#| echo: false
gt_tab <- gt_tab |>
  tab_row_group(
    rows = c(1, 3),
    label = md("_Espécies principais_")
  )
gt_tab
```

\normalsize

## Rótulo (legenda) para grupo de linhas\newline Exercício

Inclua um _rótulo_ para as linhas `pardas` e `pretas` com o texto "negras" no objeto `gt_tab`.

## Rótulo (legenda) para grupo de colunas

`tab_spanner`: permite _rótulo_ para grupo de colunas.

\small

```{r}
#| eval: false
gt_tab <- gt_tab |>
  tab_spanner(
    columns = c(
      q1_petala,
      q2_petala,
      q3_petala
    ),
    label = "Quantis"
  ) |>
  tab_spanner(
    columns = c(dp_petala, cv_petala),
    label = "Dispersão"
  )
gt_tab
```

\normalsize

---

\footnotesize

```{r}
#| echo: false
gt_tab <- gt_tab |>
  tab_spanner(
    columns = c(
      q1_petala,
      q2_petala,
      q3_petala
    ),
    label = "Quantis"
  ) |>
  tab_spanner(
    columns = c(dp_petala, cv_petala),
    label = "Dispersão"
  )
gt_tab
```

\normalsize

## Rótulo (legenda) para grupo de colunas\newline Exercício

Inclua um _rótulo_ pra as colunas do primeiro quartil, segundo quartil e terceiro quartil com o texto "Quartis" no objeto `gt_tab`.

## Movendo as colunas na tabela

* `cols_move_to_start`: move uma ou mais colunas para o início da tabela.
* `cols_move_to_end`: move uma ou mais colunas para o fim da tabela.
* `cols_move`: move uma ou mais colunas para depois um determinada coluna.

```{r}
#| eval: false
gt_tab <- gt_tab |>
  cols_move_to_start(
    columns = c(especies, dp_petala, cv_petala)
  ) |>
  cols_move_to_end(
    columns = m_petala
  ) |>
  cols_move(
    after = cv_petala,
    columns = c(q1_petala, q2_petala, q3_petala)
  )
gt_tab
```

---

\footnotesize

```{r}
#| echo: false
gt_tab <- gt_tab |>
  cols_move_to_start(
    columns = c(especies, dp_petala, cv_petala)
  ) |>
  cols_move_to_end(
    columns = m_petala
  ) |>
  cols_move(
    after = cv_petala,
    columns = c(q1_petala, q2_petala, q3_petala)
  )
gt_tab
```

\normalsize

## Movendo as colunas na tabela\newline Exercício

Deixe as colunas de `gt_tab` na seguinte ordem: _raça_, _média_, _primeiro quartil_, _segundo quartil_, _terceiro quartil_ e _desvio padrão_  usando as funções `cols_move_to_start`, `cols_move` e `cols_move_to_end`.

## Atualizando as colunas

`cols_label`: permite atualizar os _rótulos_ das colunas.

```{r}
#| eval: false
gt_tab <- gt_tab |>
  cols_label(
    especies = md("**Espécies**"),
    dp_petala = "Desvio padrão",
    cv_petala = "Coeficiente de variação",
    q1_petala = md("*Q1*"),
    q2_petala = md("*Q2*"),
    q3_petala = md("*Q3*"),
    m_petala = "Média"
  )
gt_tab
```

---


```{r}
#| echo: false
gt_tab <- gt_tab |>
  cols_label(
    especies = md("**Espécies**"),
    dp_petala = "Desvio padrão",
    cv_petala = "CV",
    q1_petala = md("*Q1*"),
    q2_petala = md("*Q2*"),
    q3_petala = md("*Q3*"),
    m_petala = "Média"
  )
gt_tab
```


## Atualizando as colunas\newline Exercício

Para o objeto `gt_tab`, garante que as colunas tenham os seguintes nomes: _Raça_, _Média_, _Desvio padrão_, _Primeiro quartil_, _Segundo quartil_ e _Terceiro quartil_.

## Formatação de valores

`fmt_number`: formatação de valores numéricos de uma ou mais colunas.

```{r}
#| eval: false
gt_tab <- gt_tab |>
  fmt_number(
    columns = c(
      dp_petala, q1_petala, q2_petala,
      q3_petala, m_petala
    ),
    decimals = 2,
    dec_mark = ",",
    sep_mark = "."
  ) |>
  fmt_number(
    columns = cv_petala,
    decimals = 2,
    dec_mark = ",",
    sep_mark = ".",
    patter = "{x} \\%"
  )
gt_tab
```



---

```{r}
#| echo: false
gt_tab <- gt_tab |>
  fmt_number(
    columns = c(
      dp_petala, q1_petala, q2_petala,
      q3_petala, m_petala
    ),
    decimals = 2,
    dec_mark = ",",
    sep_mark = "."
  ) |>
  fmt_number(
    columns = cv_petala,
    decimals = 2,
    dec_mark = ",",
    sep_mark = ".",
    patter = "{x} \\%"
  )
gt_tab
```

## Formatação de valores\newline Exercício

No objeto `gt_tab`, para as colunas numéricas coloque "`,`" para o separador de casa decimal e "`.`" para o agrupador de milhar.

# Bibliografia 

## Referências

\small